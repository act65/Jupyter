{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A functional language; models, losses, optimisers, ...?\n",
    "\n",
    "\n",
    "What is the right language for describing systems of loss functions, optimisers and agents? How should they be composed and decomposed?\n",
    "\n",
    "Is it possible to make an equivalent of a universal turing machine for neural networks. Where we have a networks that we can pass a description of another network and some inputs and it can\n",
    "\n",
    "Relatedly, is there some language that can take loss functions as [first class](https://en.wikipedia.org/wiki/First-class_function) objects which can be passed around, transformed, composed, … ? Thus allowing for [high order](https://en.wikipedia.org/wiki/Higher-order_function) loss functions. Much like functions can be in functional programming (interestingly, we could make a recursive loss functions).\n",
    "\n",
    "Can we make this into a more general framework, where we can reason about how to compose and decompose parameterised (loss) functions?\n",
    "\n",
    "<!-- We can do this with tf in some senses? Connecting nets together. We just dont have ideas about what the result will be-->\n",
    "\n",
    "### Related ideas and resources\n",
    "\n",
    "* How are the layers in a neural net related to the tapes in a turing machine?\n",
    "* [Compsing neural networks for QAs](https://arxiv.org/abs/1601.01705), [Predicting parameters](https://arxiv.org/abs/1306.0543)\n",
    "* [Decoupled neural interfaces](http://arxiv.org/abs/1608.05343) decompose a global loss function into local loss functions (the functions learnt by the synthetic gradient predictors — the $M_i$s).\n",
    "* Bootstrapping loss functions (term from [Integration of DL and NS](https://arxiv.org/abs/1606.03813)\n",
    "* [Continuation optimisation](http://people.csail.mit.edu/hmobahi/pubs/aaai_2015.pdf)\n",
    "* [Curriculum learning](http://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf)\n",
    "* [Mollifying networks](http://arxiv.org/abs/1608.04980)\n",
    "* What about parameterised loss functions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First class models\n",
    "\n",
    "Need a way to sketch a network, its structure and knowledge. So we can pass that around and do ops on it, compose it, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First class losses\n",
    "\n",
    "Having the ability to communicate/compose losses efficiently? What does this mean?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
