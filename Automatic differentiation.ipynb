{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary \n",
    "\n",
    "Recursive chain rule.\n",
    "Keeping track of transformations on variables.\n",
    "\n",
    "> _Automatic differentiation is a way to find the derivative of an expression without find- ing an expression for the derivative. [Dan Kalman](http://www1.american.edu/cas/mathstat/People/kalman/pdffiles/mmgautodiff.pdf)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What?\n",
    "\n",
    "General setting. Formulation.\n",
    "\n",
    "\n",
    "\n",
    "$f: \\mathbb{R}^m \\rightarrow \\mathbb{R}^n$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain rule\n",
    "\n",
    "\n",
    "Want - $f(x+\\epsilon x′)=f(x)+\\epsilon f′(x)x′$ - aka the chain rule?\n",
    "\n",
    "$$\n",
    "z_0 = f(x), z_1 = g(X) \\\\\n",
    "z_2 = h(z_0,z_1) \\\\\n",
    "\\frac{d z_2}{d x} = \\frac{\\partial z_2}{\\partial z_0} \\frac{d z_0}{d x} + \\frac{\\partial z_2}{\\partial z_1} \\frac{d z_1}{d x}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual numbers\n",
    "\n",
    "Look into this abit? The ring of real numbers and $\\epsilon$. Symmetries?\n",
    "$(a + b\\epsilon)(a + b\\epsilon) = a^2 + 2ab\\epsilon + \\epsilon^2\\\\ $\n",
    "\n",
    "Nilpotent $\\epsilon \\implies \\epsilon^2 = 0$\n",
    "\n",
    "https://en.wikipedia.org/wiki/Dual_number\n",
    "\n",
    "## Lifting algebra\n",
    "\n",
    "What does this mean?\n",
    "\n",
    "### Linear (matrix) representation\n",
    "$$\n",
    "a + b\\epsilon \\rightarrow\n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "0 & a \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "0 & a \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "0 & a \\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "a^2 & 2ab \\\\\n",
    "0 & a^2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Similarity to complex number's matrix representation\n",
    "\n",
    "$$\n",
    "a + \\imath b \\rightarrow\n",
    "\\begin{bmatrix}\n",
    "a & -b \\\\\n",
    "b & a \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "\\begin{bmatrix}\n",
    "a & -b \\\\\n",
    "b & a \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a & -b \\\\\n",
    "b & a \\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "a^2-b^2 & -2ab \\\\\n",
    "2ab & a^2 - b^2 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "https://en.wikipedia.org/wiki/Complex_number#Matrix_representation_of_complex_numbers\n",
    "\n",
    "### Simple example in haskell\n",
    "\n",
    "[Haskell implementation](http://www.danielbrice.net/blog/10/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dual {x = 8.0, dx = 2.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- define Dual numbers to be a pair\n",
    "data Dual = Dual  {x :: Float, dx :: Float}  deriving (Show,Eq)\n",
    "-- overload operators/define algebra\n",
    "instance Num Dual where \n",
    "    (Dual x x') + (Dual y y') = Dual (x + y) (x' + y') -- sum rule\n",
    "    (Dual x x') - (Dual y y') = Dual (x - y) (x' - y') \n",
    "    (Dual x x') * (Dual y y') = Dual (x * y) (x * y' + x' * y) -- product rule\n",
    "instance Fractional Dual where\n",
    "    (Dual x x') / (Dual y y') = Dual (x / y) ((y * y' - x * x') / y*y) -- quotient rule\n",
    "    fromRational x = Dual (fromRational x) 0\n",
    "-- test\n",
    "let f x1 x2 = x1*x2 in f(Dual 4 1)(Dual 2 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dual {x = 0.5418116, dx = -19.252117}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- overload elementary functions \n",
    "instance Floating Dual where \n",
    "    sin (Dual x x') = Dual (sin x) (x' * cos x) \n",
    "    cos (Dual x x') = Dual (cos x) (x' * (-(sin x))) \n",
    "    exp (Dual x x') = Dual (exp x) (x' * exp x)\n",
    "-- test\n",
    "let f x1 x2 = x2 * sin((x1 * x1) + 3.0) in f(Dual 5 1)(Dual 2 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "* Doesnt work for partial derivatives.\n",
    "* The cool thing is that this algebra encodes the idea of the chain rule, ... Its grammar ? enforces the chain rule, as well as the usual binary operations.\n",
    "\n",
    "## Geometry\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taylor series\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Automatic integration\n",
    "What about integration? Well the taylor series expansion of any function is $f(x) \\mid_a = f(a)+{\\frac {f'(a)}{1!}}(x-a)+{\\frac {f''(a)}{2!}}(x-a)^{2}+{\\frac {f'''(a)}{3!}}(x-a)^{3}+\\cdots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational complexity\n",
    "Lets find some bounds on complexty.. O(??). Time and space.\n",
    "\n",
    "Fundamentally, what information is required to calculate a derivative?\n",
    "What is the algorithm?\n",
    "\n",
    "## Automatic vs symbolic\n",
    "__Why is automatic faster than symbolic?__\n",
    "\n",
    "> Symbolic generation of derivatives can lead to exponential growth in the length of expressions [Dan Kalman]\n",
    "\n",
    "Proof? Why??\n",
    "\n",
    "At no point do we need to rearrange equations, substitute, manipulate, ... etc.\n",
    "\n",
    "\n",
    "## Forward mode: m > 1, n = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Reverse mode: m = 1, n > 1\n",
    "\n",
    "> spatial complexity is usually proportional to the time complexity of the original program [Griewank 1992](ftp://ftp.mcs.anl.gov/pub/tech_reports/reports/P228.pdf)\n",
    "\n",
    "aka long time dependencies will not work! (linear time dependency for 1000 transformations/operations per second means \n",
    "Need a way to solve this?!? -- maybe this isnt such a big problem...?)\n",
    "* checkpoint, TD learning?\n",
    "* skip connections? (not really a solution... unless we forget a bunch of them)\n",
    "* \n",
    "\n",
    "## Forward or reverse??  m > 1, n > 1\n",
    "\n",
    "> _For n > 1 and m > 1 there is a golden mean, but finding the optimal way is probably an NP-hard problem_ [lec notes](http://www.robots.ox.ac.uk/~tvg/publications/talks/autodiff.pdf) \n",
    "\n",
    "## Ideas\n",
    "\n",
    "* Parameter tying. How can we take advantage of variables that have the same functions applied to them? (well the parameter should be tied in the original model, we should be dealing with it here?!?)\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix-calculus AD\n",
    "\n",
    "Reverse - trace?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backprop\n",
    "\n",
    "Is a special case.\n",
    "\n",
    "\n",
    "http://neuralnetworksanddeeplearning.com/chap2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How?\n",
    "\n",
    "### Source code transformation\n",
    "\n",
    "\n",
    "\n",
    "### Operator-overloading\n",
    "\n",
    "\n",
    "### New programming language...\n",
    "\n",
    "\n",
    "### ??? Ideas?\n",
    "\n",
    "\n",
    "\n",
    "### Issues\n",
    "\n",
    "* Need to be sufficiently smooth so that higher order derivatives are cts.\n",
    "* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "\n",
    "> and where differentiating an approximation to $f$ produces much worse answers than explicitly approximating the (known) derivative of $f$. [alexey radul](http://alexey.radul.name/ideas/2013/introduction-to-automatic-differentiation/)\n",
    "\n",
    "E.g. numerical integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "### Automatic differentiation\n",
    "* [Great intro](http://alexey.radul.name/ideas/2013/introduction-to-automatic-differentiation/)\n",
    "* http://conal.net/blog/posts/what-is-automatic-differentiation-and-why-does-it-work\n",
    "* http://conway.rutgers.edu/~ccshan/wiki/blog/posts/Differentiation/\n",
    "* http://blog.sigfpe.com/2005/07/automatic-differentiation.html\n",
    "* [Julia implementation](http://int8.io/automatic-differentiation-machine-learning-julia/#Reverse_mode_automatic_differentiation_8211_basic_bits)\n",
    "\n",
    "### Backprop\n",
    "\n",
    "* http://int8.io/backpropagation-from-scratch-in-julia-part-ii-derivation-and-implementation/\n",
    "* http://colah.github.io/posts/2015-08-Backprop/\n",
    "\n",
    "### Other\n",
    "* https://en.wikipedia.org/wiki/Dual_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions and thoughts\n",
    "\n",
    "\n",
    "\n",
    "* How is this related to functional programming and transforms on data?\n",
    "* Relation to dynamic programming (colah mentioned this)\n",
    "* Answer: Why is automatic better than symbolic?\n",
    "* Investigate the geometry of dual numbers.\n",
    "* Make an AD module in haskell.\n",
    "* Contribute to autograd.\n",
    "* Figure out relation to taylor expansion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell",
   "language": "haskell",
   "name": "haskell"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "name": "haskell",
   "version": "7.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
