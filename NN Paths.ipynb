{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width = 64 Paths = 7840         \tDepth = 1 Paths = 7840\n",
      "Width = 128 Paths = 501760         \tDepth = 2 Paths = 501760\n",
      "Width = 192 Paths = 1003520         \tDepth = 3 Paths = 32112640\n",
      "Width = 256 Paths = 1505280         \tDepth = 4 Paths = 2055208960\n",
      "Width = 320 Paths = 2007040         \tDepth = 5 Paths = 131533373440\n",
      "Width = 384 Paths = 2508800         \tDepth = 6 Paths = 8418135900160\n",
      "Width = 448 Paths = 3010560         \tDepth = 7 Paths = 538760697610240\n",
      "Width = 512 Paths = 3512320         \tDepth = 8 Paths = 34480684647055360\n",
      "Width = 576 Paths = 4014080         \tDepth = 9 Paths = 2206763817411543040\n"
     ]
    }
   ],
   "source": [
    "inputs = 784\n",
    "outputs = 10\n",
    "width = depth = 1\n",
    "p = 64\n",
    "for i in range(1,10):\n",
    "    print('Width = {} Paths = {}         \\tDepth = {} Paths = {}'.format(\n",
    "            i*p,np.prod([inputs,width,outputs]),\n",
    "            i,np.prod([inputs,depth,outputs])))\n",
    "    #add p nodes each time\n",
    "    width += p if i != 1 else p-1\n",
    "    depth *= p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That almost seems ridiculous, it increases faster than factorial in the depth (somewhat depends on width and depth). A deep net, ie 1000 layers of 50 neurons (i.e. $50^{1000}$) has about 2000 times more paths than atoms in the universe... I should prove it more formally. Make a picture.\n",
    "\n",
    "How does the number of required operations change with each?\n",
    "* For added width (of p nodes) we need an additional matmul by pxp.\n",
    "* For each added layer of depth (of p nodes) we are adding a matmul by pxp.\n",
    "(need to formulate more rigorously.)\n",
    "\n",
    "\n",
    "## Questions\n",
    "* Does the computational complexity also increase with the number of paths? No, I dont think so? Why? A nice feature of its' linearity? Ok, so now we just need to show that more paths equals greater representative power? How?\n",
    "* So what does the non-linearity buy us? What can complex numbers buy us? A way to achieve non-linear interactions (entanglement, constructive and destructive interference) while remaining linear??\n",
    "* How are subnetworks from dropout related to paths?\n",
    "* What if we could trace the 'most important paths', what could they tell us?\n",
    "* If n_paths(wideNet) == n_paths(deepNet), then does wideNet == deepNet? \n",
    "    * probably not. we have weight tying across paths in the deep net -- how/why is this important? to do with the structure in the paths. what symmetries are there, can we foumulate using some sort of group theory?)\n",
    "    * is there some sort of useful metric/ratio? paths/parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
