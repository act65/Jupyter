{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Causal strength\n",
    "* Confounding\n",
    "* Interventions\n",
    "* Counter factuals\n",
    "\n",
    "\n",
    "https://ei.is.tuebingen.mpg.de/research_projects/causal-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let consider a simple example\n",
    "\n",
    "**Good/bad/ugly**\n",
    "\n",
    "We have 3 events, a child being good (P(g=1)=0.7), a child being bad (P(b=1)=0.5), and a child being given a lolly. A child being given a lolly is caused by the child being good (P(l=1|g=1) = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = 1000\n",
    "#Generate some 'observed' data\n",
    "good = np.array([1 if x<0.9 else 0 for x in np.random.random(n)]) \n",
    "bad = np.array([1 if x<0.3 else 0 for x in np.random.random(n)])  #\n",
    "attention = np.array([1 if good[i] else 0 for i in range(n)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Marginal probabilities are calculated as the sum of events occured divided by the potential amount of times they could have occured.\n",
    "* Joint probabilities can be calculated by simply multiplying the marginal probabilities. P(A,B) = P(A) * P(B). However, this makes the assumption that A and B are independent (this will lead to problems)\n",
    "* Conditional probabilities can be calculated by taking the joint probability of the two events and dividing it by the marginal probability of whichever event is given. P(A|B) = P(A,B)/P(B)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal probabilities - (priors)\n",
      "---  -----\n",
      "g=1  0.892\n",
      "b=1  0.317\n",
      "l=1  0.892\n",
      "g=0  0.108\n",
      "b=0  0.683\n",
      "l=0  0.108\n",
      "---  -----\n",
      "Joint probabilities\n",
      "--------------  ----------\n",
      "P(g=1,b=1)      0.282764\n",
      "P(g=1,l=1)      0.795664\n",
      "P(g=1,g=0)      0.096336\n",
      "P(g=1,b=0)      0.609236\n",
      "P(g=1,l=0)      0.096336\n",
      "P(b=1,l=1)      0.282764\n",
      "P(b=1,g=0)      0.034236\n",
      "P(b=1,b=0)      0.216511\n",
      "P(b=1,l=0)      0.034236\n",
      "P(l=1,g=0)      0.096336\n",
      "P(l=1,b=0)      0.609236\n",
      "P(l=1,l=0)      0.096336\n",
      "P(g=0,b=0)      0.073764\n",
      "P(g=0,l=0)      0.011664\n",
      "P(b=0,l=0)      0.073764\n",
      "P(g=1,l=1,b=0)  0.543439\n",
      "P(g=1,l=1,l=0)  0.0859317\n",
      "P(g=1,g=0,b=0)  0.0657975\n",
      "P(g=1,g=0,l=0)  0.0104043\n",
      "P(b=1,l=1,b=0)  0.193128\n",
      "P(b=1,l=1,l=0)  0.0305385\n",
      "P(b=1,g=0,b=0)  0.0233832\n",
      "P(b=1,g=0,l=0)  0.00369749\n",
      "--------------  ----------\n"
     ]
    }
   ],
   "source": [
    "import tabulate as tab\n",
    "#Calculating priors from observed data\n",
    "#Marginal probabilities\n",
    "tags = ['g=1','b=1','l=1','g=0','b=0','l=0']\n",
    "mP = np.array([np.sum(good)/len(good),np.sum(bad)/len(bad),np.sum(attention)/len(attention)])\n",
    "mP = np.concatenate((mP,1-mP),axis = 0)\n",
    "MP = list(zip(tags,list(mP)))\n",
    "print('Marginal probabilities - (priors)')\n",
    "print(tab.tabulate(MP))\n",
    "\n",
    "#Joint probabilities\n",
    "jP = []\n",
    "n = len(MP)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if i<j:\n",
    "            jP.append([ ( 'P(' + MP[i][0] + ',' + MP[j][0]) + ')'\n",
    "                       , MP[i][1]*MP[j][1]]) \n",
    "for i in range(0,2):\n",
    "    for j in range(2,4):\n",
    "        for k in range(4,6):\n",
    "            jP.append([  'P(' + MP[i][0] + ',' + MP[j][0] + ',' + MP[k][0]+ ')'\n",
    "           , MP[i][1]*MP[j][1]*MP[k][1] ])\n",
    "print('Joint probabilities')\n",
    "print(tab.tabulate(jP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the conditional probabilities is pointless using the equation P(A|B) = P(A,B)/P(B) as it will simply return P(A). \n",
    "\n",
    "* Why do these probabilties make little sense? For example we know that P(l=1,g=1) = P(g=1) x P(l=1|g=1) = 1x0.7.\n",
    "* And why can we not figure out the conditional probabilities. \n",
    "\n",
    "The problem is that our initial system doesnt use any information about the causal structure of these variables. So, how can we figure out that attention depends on good/bad?\n",
    "  \n",
    "Firstly, we have ignored information about how events are correlated. We can calculate the conditional probabilities from correlations. Which we can use to claculate the joint probabilities.\n",
    "\n",
    "\n",
    "So how can we infer causality from these joint and conditional prababilities? What patterns are there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional probabilities calculated with correlations\n",
      "----------  ---------\n",
      "P(g=1|b=1)  0.902208\n",
      "P(g=0|b=0)  0.0977918\n",
      "P(g=1|l=1)  1\n",
      "P(g=0|l=0)  0\n",
      "P(b=1|g=1)  0.320628\n",
      "P(b=0|g=0)  0.679372\n",
      "P(b=1|l=1)  0.320628\n",
      "P(b=0|l=0)  0.679372\n",
      "P(l=1|g=1)  1\n",
      "P(l=0|g=0)  0\n",
      "P(l=1|b=1)  0.902208\n",
      "P(l=0|b=0)  0.0977918\n",
      "----------  ---------\n",
      "Joint probabilities calculated from conditionals\n",
      "----------  ---------\n",
      "P(g=1,b=1)  0.286\n",
      "P(g=0,b=0)  0.714\n",
      "P(g=1,l=1)  0.80477\n",
      "P(g=0,l=0)  0.714\n",
      "P(b=1,g=1)  0.0872303\n",
      "P(b=0,g=0)  0.286\n",
      "P(b=1,l=1)  0.0872303\n",
      "P(b=0,l=0)  0.286\n",
      "P(l=1,g=1)  0.892\n",
      "P(l=0,g=0)  0.19523\n",
      "P(l=1,b=1)  0.317\n",
      "P(l=0,b=0)  0.19523\n",
      "----------  ---------\n"
     ]
    }
   ],
   "source": [
    "#Recalculating using correlations\n",
    "def corr(a,b,c=[]): #conditional probability of a given b\n",
    "    return np.sum(a*b)/(np.sum(b) + np.sum(c))\n",
    "\n",
    "data = [good,bad,attention]\n",
    "cP = []\n",
    "jP = []\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i != j:\n",
    "            #Conditional probabilities\n",
    "            cP.append([ 'P(' + tags[i] +'|' + tags[j] + ')',\n",
    "                    corr(data[i],data[j])])\n",
    "            cP.append([ 'P(' + tags[i+3] +'|' + tags[j+3] + ')',\n",
    "                    1-cP[-1][1] ])\n",
    "            \n",
    "            \n",
    "            #Joint probabilities\n",
    "            jP.append([ 'P(' + tags[i] +',' + tags[j] + ')',\n",
    "                    cP[i][1]*MP[j][1]   ])\n",
    "            jP.append([ 'P(' + tags[i+3] +',' + tags[j+3] + ')',\n",
    "                    1-jP[i][1]  ])\n",
    "\"\"\"         \n",
    "            for k in range(3):\n",
    "                if i != k:\n",
    "                    cP.append([  'P(' + tags[i] +'|' + tags[j] + ',' + tags[k] ')',\n",
    "                            ]) \n",
    "\n",
    "                    cP.append([  'P(' + tags[i] + ','  + tags[j] +'|'+ tags[k] ')',\n",
    "                            ]) \n",
    "\"\"\"\n",
    "print('Conditional probabilities calculated with correlations')       \n",
    "print(tab.tabulate(cP))\n",
    "print('Joint probabilities calculated from conditionals')\n",
    "print(tab.tabulate(jP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that P(a=1|g=1) = 1, which tells us that these two variables are perfectly correlated. How do we infer causality?\n",
    "\n",
    "So if some event, which we will call A, happens a high amount of the time (>70%) then A will be highly correlated with other events. So, how do we distinguish whether A is causing other events or just an independent variable that always seems to be present?\n",
    "\n",
    "Well, if other events occur just once without A then A cannot be the cause. But then you need to consider noise and the chance that you are not observing the true state of the events... So that doesnt really help us, unless we can integrate a probabalistic model of the expected amount of noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now consider this for non binary variables. This will require distrubutions of probability to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good = np.random.randn(n)\n",
    "bad = np.random.randn(n)\n",
    "attention = np.greater(0.5,good+bad) #should this be binary? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Questions\n",
    "* How should these probabilities be represented in a network? How can a neural network capture explaining away?\n",
    "* How should a neural network represent marginal, joint and conditional probabilities? Or should it calculate them?\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Generating a model of priors from observed data with a neural net. How? Local vs distributed represetation? Learning... Embedding high dim vectors???\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions and notes\n",
    "* So in calculating the marginal porbabilities we have assumed that variables cannot be in a superposition of states.\n",
    "* What if we dont have the ability to recognise, for certain, when and which events are occuring.\n",
    "* How should a new piece of information effect the system? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
