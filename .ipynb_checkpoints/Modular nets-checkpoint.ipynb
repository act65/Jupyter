{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A formal language for composing networks\n",
    "\n",
    "Aka weight tying at a bigger, more complex, more structured scale\n",
    "\n",
    "<img src=\"Images/PoggioModnet.png\" alt=\"Modnet\">\n",
    "\n",
    "\n",
    "I like viewing networks at a higher level. Where instead of considering the connections between neurons we are considering the connections between networks. (although it is really the same thing, as a neuron is just some function).\n",
    "\n",
    "<img src=\"Images/PoggioModnetmat.png\" alt=\"Modnetmat\">\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 0 & A & 0 \\\\ 0 & 0 & B \\\\ C & 0 & D \\end{bmatrix} \\left[ \\begin{array}{c} x \\\\ y \\\\ z \\end{array} \\right] =  \\left[ \\begin{array}{c} Ay \\\\ Bz \\\\ Cx + Dz \\end{array} \\right] \\rightarrow \\left[ \\begin{array}{c} x \\\\ y \\\\ z \\end{array} \\right]\\\\\\\\\n",
    "$$\n",
    "$$\n",
    "x_{t+1} = A y_t \\\\\n",
    "y_{t+1} = B z_t \\\\\n",
    "z_{t+1} = C x_t + D  z_t\n",
    "$$\n",
    "\n",
    "So all we have to do is replace our non-linearity in $\\sigma(\\phi \\cdot W + b)$ with a neural network, $NN(\\phi \\cdot W + b)$? No, it's not quite that simple... As we want different non-linearities for different states.\n",
    "$$\n",
    "\\begin{bmatrix} 0 & A & 0 \\\\ 0 & 0 & B \\\\ C & 0 & D \\end{bmatrix} \\left[ \\begin{array}{c} x \\\\ y \\\\ z \\end{array} \\right] =  \\left[ \\begin{array}{c} A(y) \\\\ B(z) \\\\ C(x) + D(z) \\end{array} \\right] \\rightarrow \\left[ \\begin{array}{c} x \\\\ y \\\\ z \\end{array} \\right]\\\\\n",
    "$$\n",
    "Which would be equivalent to \n",
    "$$\n",
    "x_{t+1} = A(y_t) \\\\\n",
    "y_{t+1} = B(z_t) \\\\\n",
    "z_{t+1} = C(x_t) + D(z_t)\n",
    "$$\n",
    "\n",
    "Where;\n",
    "* x,y,z are tensors. \n",
    "* A,B,C,D are neural networks. E.g. A = a 2x5x3 layer feedforward neural net. B = a 10 neuron RNN. ...\n",
    "\n",
    "### Higher levels\n",
    "\n",
    "I would then want to be able to say\n",
    "\n",
    "$$\n",
    "E = \\begin{bmatrix} 0 & A & 0 \\\\ 0 & 0 & B \\\\ C & 0 & D \\end{bmatrix} \\\\\n",
    "F = \\begin{bmatrix} A & B & B \\\\ 0 & 0 & C \\\\ D & D & 0 \\end{bmatrix} \\\\\n",
    "G = \\begin{bmatrix} 0 & A & 0 \\\\ 0 & C & B \\\\ 0 & 0 & D \\end{bmatrix} \\\\\n",
    "H = \\begin{bmatrix} 0 & 0 & D \\\\ C & 0 & B \\\\ 0 & A & 0 \\end{bmatrix} \\\\\n",
    "$$\n",
    "and finally\n",
    "$$\n",
    "I = \\begin{bmatrix} E & F & 0 \\\\ A & 0 & B \\\\ C & H & D \\end{bmatrix} \\\\\n",
    "$$\n",
    "on so on and so forth, for as many higher 'levels' as I wanted.\n",
    "\n",
    "### Issues and fundamental questions;\n",
    "* C(x) + D(z) can only be evaluated properly if;\n",
    "    * the inputs are the right shape, f(x) takes 5x1 but recieves 10x3...\n",
    "    * the outputs are the right shape. f(x) returns 2x1 and g(y) returns 3x5. how can these be composed together?\n",
    "        * We could make all nets input/output the same shape?\n",
    "        * We could create a basis type that all our nets can recieve. Anything else gets (un)raveled?\n",
    "* What would be the basic building block?\n",
    "    * the linear neuron? probably not\n",
    "    * Also these need to be able to proparage forward in time for RNNs.\n",
    "    \n",
    "    \n",
    "### Interestingly we could build;\n",
    "* traditional activation functions from a network of less complex neurons. Thus a universal net?\n",
    "* a RNN with neurons that are RNNs themselves, thus giving time-dependent activity, or memory.\n",
    "* So pretty much any neural network architecture is a special case of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation?? (universal??)\n",
    "\n",
    "### Conv net\n",
    "What would a conv net look like, when composed from simpler parts?\n",
    "\n",
    "Image we have a kernel/filter/neuron A in a conv layer. Then,\n",
    "\n",
    "15x7 x 7x1\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    ". & . & . & 0 & 0 & 0 & 0 \\\\ \n",
    ". & A & . & 0 & 0 & 0 & 0 \\\\ \n",
    ". & . & . & 0 & 0 & 0 & 0 \\\\ \n",
    "0 & . & . & . & 0 & 0 & 0 \\\\ \n",
    "0 & . & A & . & 0 & 0 & 0 \\\\\n",
    "0 & . & . & . & 0 & 0 & 0 \\\\ \n",
    "0 & 0 & . & . & . & 0 & 0 \\\\ \n",
    "0 & 0 & . & A & . & 0 & 0 \\\\ \n",
    "0 & 0 & . & . & . & 0 & 0 \\\\ \n",
    "0 & 0 & 0 & . & . & . & 0 \\\\ \n",
    "0 & 0 & 0 & . & A & . & 0 \\\\ \n",
    "0 & 0 & 0 & . & . & . & 0 \\\\ \n",
    "0 & 0 & 0 & 0 & . & . & . \\\\ \n",
    "0 & 0 & 0 & 0 & . & A & . \\\\ \n",
    "0 & 0 & 0 & 0 & . & . & . \\\\ \n",
    "\\end{bmatrix}  \\left[ \\begin{array}{c} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\\\ x_6\\\\ x_7\\\\ \\end{array} \\right] = \\left[ \\begin{array}{c} y_1 \\\\ y_2 \\\\ y_3 \\\\ y_4 \\\\ y_5 \\\\ y_6\\\\ y_7\\\\ y_8 \\\\ y_9 \\\\ y_{10} \\\\ y_{11} \\\\ y_{12} \\\\ y_{13}\\\\ y_{14}\\\\ y_{15} \\\\ \\end{array} \\right] \\rightarrow  \\left[ \\begin{array}{c} y_1 + y_2 + y_3 \\\\ y_4 + y_5 + y_6\\\\ y_7 + y_8 + y_9 \\\\ y_{10} + y_{11} + y_{12} \\\\ y_{13} + y_{14} + y_{15} \\\\ \\end{array} \\right]\n",
    "$$\n",
    "\n",
    "##### Multi-layer??\n",
    "What about a multilayer conv net?? How can I represent that with this language?\n",
    "\n",
    "##### R-CNN?\n",
    "\n",
    "Def $B: \\vec{x} \\rightarrow \\vec{z}$ such that $\\vec{z} = A \\ast \\vec{x}$\n",
    "\n",
    "$$\n",
    "RCNN = \\begin{bmatrix} 0 & B \\\\ B & 0 \\\\ \\end{bmatrix}\n",
    "$$\n",
    "so x = B(y) and y = B(x), a recurrent net (kinda - without states).\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "0&0&0&0&0&0&0& . & . & . & 0 & 0 & 0 & 0 \\\\ \n",
    "0&0&0&0&0&0&0& . & A & . & 0 & 0 & 0 & 0 \\\\ \n",
    "0&0&0&0&0&0&0& . & . & . & 0 & 0 & 0 & 0 \\\\ \n",
    "0&0&0&0&0&0&0& 0 & . & . & . & 0 & 0 & 0 \\\\ \n",
    "0&0&0&0&0&0&0& 0 & . & A & . & 0 & 0 & 0 \\\\\n",
    "0&0&0&0&0&0&0& 0 & . & . & . & 0 & 0 & 0 \\\\ \n",
    "0&0&0&0&0&0&0& 0 & 0 & . & . & . & 0 & 0 \\\\ \n",
    "0&0&0&0&0&0&0& 0 & 0 & . & A & . & 0 & 0 \\\\ \n",
    "0&0&0&0&0&0&0& 0 & 0 & . & . & . & 0 & 0 \\\\ \n",
    "0&0&0&0&0&0&0& 0 & 0 & 0 & . & . & . & 0 \\\\ \n",
    "0&0&0&0&0&0&0& 0 & 0 & 0 & . & A & . & 0 \\\\ \n",
    "0&0&0&0&0&0&0& 0 & 0 & 0 & . & . & . & 0 \\\\ \n",
    "0&0&0&0&0&0&0& 0 & 0 & 0 & 0 & . & . & . \\\\ \n",
    "0&0&0&0&0&0&0& 0 & 0 & 0 & 0 & . & A & . \\\\ \n",
    "0&0&0&0&0&0&0& 0 & 0 & 0 & 0 & . & . & . \\\\ \n",
    ". & . & . & 0 & 0 & 0 & 0 &0&0&0&0&0&0&0\\\\ \n",
    ". & A & . & 0 & 0 & 0 & 0 &0&0&0&0&0&0&0\\\\ \n",
    ". & . & . & 0 & 0 & 0 & 0 &0&0&0&0&0&0&0\\\\ \n",
    "0 & . & . & . & 0 & 0 & 0 &0&0&0&0&0&0&0\\\\ \n",
    "0 & . & A & . & 0 & 0 & 0 &0&0&0&0&0&0&0\\\\\n",
    "0 & . & . & . & 0 & 0 & 0 &0&0&0&0&0&0&0\\\\ \n",
    "0 & 0 & . & . & . & 0 & 0 &0&0&0&0&0&0&0\\\\ \n",
    "0 & 0 & . & A & . & 0 & 0 &0&0&0&0&0&0&0\\\\ \n",
    "0 & 0 & . & . & . & 0 & 0 &0&0&0&0&0&0&0\\\\ \n",
    "0 & 0 & 0 & . & . & . & 0 &0&0&0&0&0&0&0\\\\ \n",
    "0 & 0 & 0 & . & A & . & 0 &0&0&0&0&0&0&0\\\\ \n",
    "0 & 0 & 0 & . & . & . & 0 &0&0&0&0&0&0&0\\\\ \n",
    "0 & 0 & 0 & 0 & . & . & . &0&0&0&0&0&0&0\\\\ \n",
    "0 & 0 & 0 & 0 & . & A & . &0&0&0&0&0&0&0\\\\ \n",
    "0 & 0 & 0 & 0 & . & . & . &0&0&0&0&0&0&0\\\\\n",
    "\\end{bmatrix}\n",
    "\\left[ \\begin{array}{c} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\\\ x_5 \\\\ x_6\\\\ x_7\\\\ y_1 \\\\ y_2 \\\\ y_3 \\\\ y_4 \\\\ y_5 \\\\ y_6\\\\ y_7\\\\\\end{array} \\right] = \\left[ \\begin{array}{c} z_1 \\\\ z_2 \\\\ z_3 \\\\ z_4 \\\\ z_5 \\\\ z_6\\\\ z_7\\\\ z_8 \\\\ z_9 \\\\ z_{10} \\\\ z_{11} \\\\ z_{12} \\\\ z_{13}\\\\ z_{14}\\\\ z_{15}\\\\ z_{16} \\\\ z_{17} \\\\ z_{18} \\\\ z_{19} \\\\ z_{20} \\\\ z_{21}\\\\ z_{22}\\\\ z_{23} \\\\ z_{24} \\\\ z_{25} \\\\ z_{26} \\\\ z_{27} \\\\ z_{28}\\\\ z_{29}\\\\ z_{30} \\\\ \\end{array} \\right] \\rightarrow Oh...\n",
    "$$\n",
    "\n",
    "\n",
    "### RNN\n",
    "\n",
    "\n",
    "### Resnet\n",
    "\n",
    "\n",
    "### other nets? ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
