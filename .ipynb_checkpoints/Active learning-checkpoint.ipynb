{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries as reinforcement learning??\n",
    "\n",
    "* Query = action\n",
    "* Set of queries = policy\n",
    "* etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import data, oracle   # oracle(x) = data\n",
    "patterns = cluster(data) #some unsupervised method to find patterns, clustering?\n",
    "\n",
    "#initialise a NN based on what we know from the patterns <- how???\n",
    "model = NeuralNet(patterns)  #generate a NN based on the patterns found\n",
    "\n",
    "import ActiveLearner\n",
    "NN_depth, NN_breadth = ActiveLearner(self, patterns) #given its past experience and contextual info\n",
    "\n",
    "while not target_accuracy: #and suitable sample size?\n",
    "    \n",
    "    for b in breadth:\n",
    "        # pick a leaf (aka query) to explore\n",
    "        Leaf = NN_breadth.choose_likely_leaf() #random query biased by experience and context\n",
    "        queries.append(Leaf) #canidate queries\n",
    "        \n",
    "        #explore leaf with MCTS\n",
    "        for m in MCTS:\n",
    "            \n",
    "            #pick actions randomly to depth d, thus making a policy\n",
    "            for d in depth: \n",
    "                query_policy.append(MC.random_query()) #could do better than random?, recycle NN_breadth?? \n",
    "            \n",
    "            #evaluate the policy.\n",
    "            leaf_policy_values.append(NN_depth.predict_value(query_policy)) \n",
    "            #aka - predict the accuracy of a net trained with the query - result pair\n",
    "        \n",
    "        #average value across all explored policies for the leaf - could be better than average?\n",
    "        values.append( mean(leaf_policy_values) )\n",
    "    \n",
    "    #ask query that is predicted to (on average) give the greatest accuracy\n",
    "    q = queries(argmax(values))\n",
    "    r = oracle.query(q) \n",
    "    \n",
    "    #train our model and test it\n",
    "    model.train(q,r) #back prop. but also need some way to change topology??\n",
    "    if model.test() > tol:  \n",
    "        target_accuracy = True\n",
    "        #but how can we actually test it without labeled data?!? \n",
    "        #we need a decent sample? \n",
    "        #or can it just be assumed/inferred from the patterns in the clusters and a validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this doesnt optimise for the shortest set of queries? Or does it, like A\\*, or greedy search?\n",
    "\n",
    "Train the active learner somehow... reinforce... (need to figure this out)\n",
    "\n",
    "\n",
    "# Thoughts and questions\n",
    "\n",
    "\n",
    "How can unsupervised techniques like clustering help us decide;\n",
    "* what queries to ask?\n",
    "* what solutions are likely? (topology of the net)\n",
    "Also, how can we intelligently change the topology of a network based on training pairs?\n",
    "\n",
    "\n",
    "*****\n",
    "\n",
    "\n",
    "* Correct results can only ever infer hypotheses (with probabilities??) \n",
    "    * Although, we can also use occams razor to help us choose a solution/explanation...\n",
    "* So, one query 'rules out'/falsifies a subset of potential weights/solutions/explanations, iff it is wrong. \n",
    "    * So traditional ML does not use the information given by mistakes to its fullest potential? \n",
    "    * Noise <- causes problems.\n",
    "        * You can also make mistakes due to noise... \n",
    "        * But we can use probabilities to try to figure out if mistakes are generated by noise or by error\n",
    "            * But, we would have to make an assumption about the noise, is there a way around this??\n",
    "* The remaining weight space is/are the plasuible hypotheses.\n",
    "    * How can we cut this weight space down as quickly as possible?\n",
    "        * Make errors. \n",
    "            * But how would it choose which inputs it wants to (try to) falisify? (or what queries it wants to ask)\n",
    "                * Queries are biased on past experience (like the breadth net from AlphaGO)\n",
    "            * What sort of input-output pair gives the most information? The largest set of weights/explanations we can remove\n",
    "        * This reduces the computational load for inference. as it would have to search a smaller weight space\n",
    "    * Weight space increases exponentially with the size/complexity of the net.\n",
    "        * So a good init is important. Start small, but not too small as the solution may be missed.\n",
    "        * How do we know what size/complexity to make it? \n",
    "            * We need to be able to approximate the complexity from the queries we ask\n",
    "\n",
    "*****\n",
    "\n",
    "Assuming there is a causal relation, is it always possible to deduce the relation from falsifications? (this assumes the past will be the same as the present?? but we can just define a function as being a function of the past?) \n",
    "\n",
    "What is the maximum amount of information that can be gained from a single mistake?\n",
    "Can the solution always be improved by asking more queries??? Idealy no, but with real data, with noise, probably??\n",
    "\n",
    "Minimise the amount of queries made to the teacher (aka. What is the minimum amount of experiments I need to run to learn this function/explain this phenomena?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
