{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algebra\n",
    "\n",
    "* The probability of both $P(x = x_1)$ and $P(x = x_2)$ equals\n",
    "\n",
    "##### Margianal probability\n",
    "\n",
    "$$P(X=x,Y) = \\sum_i P(X=x,Y=y_i)$$\n",
    "Ok. So why do we add these and multiply others?\n",
    "We are accumulating all the possible ways x can happend. And unless something weird is going on, x cannot be independently present in two places. x is not independent of itself. (why does independence imply multiplication?)\n",
    "\n",
    "##### Conditional probability\n",
    "Does this make sense?\n",
    "\n",
    "$$P(Y=y|X=x) = \\frac{P(Y=y,X=x)}{P(X=x)}$$\n",
    "\n",
    "##### Chain rule\n",
    "\n",
    "* Any relation to the real chain rule?\n",
    "* This feels like a decomposition?!? How do probability decompositions relate to tensor decompositions? And what are they really doing? Finding patterns? It's compression?\n",
    "$$P(x^1,x^2,...,x^n) = P(x^1 | x^2, ..., x^n ) P(x^2, ..., x^n) $$\n",
    "\n",
    "* Why does this make sense? Oh... it's just the conditional probability equation above.\n",
    "\n",
    "$$\\mathrm {P} (A_{4},A_{3},A_{2},A_{1})=\\mathrm {P} (A_{4}\\mid A_{3},A_{2},A_{1})\\cdot \\mathrm {P} (A_{3}\\mid A_{2},A_{1})\\cdot \\mathrm {P} (A_{2}\\mid A_{1})\\cdot \\mathrm {P} (A_{1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independence\n",
    "\n",
    "* Is independence related to orthogonality in linear algebra?\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to answer/investigate\n",
    "\n",
    "* Bayesian vs frequentist?\n",
    "* Prove gaussian and uniform are the lowest entropy priors\n",
    "* Investigate stuctural equations?\n",
    "* Is there some linear algrbra/geometric interpretation? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
