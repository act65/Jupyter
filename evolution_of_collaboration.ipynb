{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evolution-of-collaboration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/act65/Notes/blob/master/evolution_of_collaboration.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "m2BBguGRKxlz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy.random as rnd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.WARNING)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UTMIF9K0NUeC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Trading makes no sense without it providing an advantage. The advantage (for all) is the increased efficiency from specialisation.\n",
        "\n",
        "Goal: maximise individual wealth (measured by ?)\n",
        "\n",
        "#### Reputation\n",
        "\n",
        "- Necessary: (multi-agent, resource and info (gossip) exchange, private ownership, conserved resources, ...?)\n",
        "- Trajectory: Steal -> Reputation\n",
        "- Problem it solves: Disincentivise bad actors\n",
        "\n",
        "#### Safe trade dances\n",
        "\n",
        "- Necessary: (bounded memory for assesing trust)\n",
        "- Trajectory: Reputation -> Safe trade dances\n",
        "- Problem it solves: reputation does not scale with many agents (requires too much memory)\n",
        "\n",
        "#### Debt\n",
        "\n",
        "- Necessary: accurate memory\n",
        "- Trajectory: Safe trade dances -> Debt/credit/lending/borrowing\n",
        "- Prblem it solves: ??\n",
        "\n",
        "\n",
        "#### (Ac)counting\n",
        "\n",
        "- Necessary: ?\n",
        "- Trajectory: Debt -> Accounting\n",
        "- Problem it solves: Keeping track of many debtors/credits (can get messy quickly)\n",
        "\n",
        "#### Money\n",
        "\n",
        "- Necessary: (resource and info (gossip) exchange?, the ability to count, \n",
        "- Trajectory: Accounting -> Money\n",
        "- Problem it solves: Factorises information in the item-item trade matrix (like a rank 1 decomposition)\n",
        "\n",
        "#### Market (aka collaboration???)\n",
        " \n",
        "- Necessary: (Harvest, safe exchange (aka trust?), bounded memory for assesing value)\n",
        "- Trajectory: ?\n",
        "- Problem it solves: individuals value estimates do not scale well with many resources (requires too much memory)\n",
        "\n",
        "#### Arbitration\n",
        "\n",
        "- Necessary: Bounded memory, partial info, \n",
        "- Trajectory: ? -> Arbitration\n",
        "- Problem it solves: Inaccurate estimates of resource values (but how does that help individuals/the rest of the market?)\n",
        "\n",
        "Other questions\n",
        "\n",
        "- How is a market like a message passing algorithm?\n"
      ]
    },
    {
      "metadata": {
        "id": "xboxz__eKVFo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trade(r1, r2, t):\n",
        "  \"\"\"\n",
        "  Want a representation that;\n",
        "  - can smoothly go from un-safe trades to safe ones to money based trade.\n",
        "  - that captures the rules of the trade, and not necessarily what is being traded.\n",
        "  - That can be learned (need a space of trading schemes).\n",
        "\n",
        "  Where does the money come from!? \n",
        "  It is a decomposition of t into what a1 and a2 value?\n",
        "  t = np.outer(a.resource_values, b.resource_values) \n",
        "  \n",
        "  Other thoughts;\n",
        "  - what about 3 party trades? How to facilitate with a two party system?\n",
        "  - What about mediators? And tusted third parties?\n",
        "  - are linear functions succifient to caputre meaningful trades?\n",
        "  - Problem is that reputation is a local fn and money is a globally agreed upon standard. \n",
        "  (that sounds similar to the gossip algorithm!?)\n",
        "  \n",
        "  Args:\n",
        "    r1 (np.array): resources of agent 1. shape = \n",
        "    r1 (np.array): resources of agent 2. shape = \n",
        "    t (np.array):\n",
        "    \n",
        "  Returns:\n",
        "    \n",
        "  \"\"\"\n",
        "  # this is where marcus' work would fit in?!\n",
        "  # simulating how the actual resources are echanged. \n",
        "  # a richer representation than just using transition matrices.\n",
        "  # would allow for a finer trajectory? steal -> holding -> safe trade ->\n",
        "  \n",
        "  \n",
        "  # represent as a graph, with t as the transition matrix.\n",
        "  # sum of the stacked columns must be 1.\n",
        "  \n",
        "  r = np.hstack([r1, r2])  # could zip instead? would make easier to !??!\n",
        "  \n",
        "  \n",
        "  r_ = np.dot(t, r)\n",
        "  return tuple(np.split(r_, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ssgM1mITaPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2b3d162f-8d8f-457e-8b40-fd203a19e295"
      },
      "cell_type": "code",
      "source": [
        "a, b = rnd.randint(0, 10, 4), rnd.randint(0, 10, 4)\n",
        "\n",
        "X = np.fliplr(np.eye(2))\n",
        "S = np.array([[1,1], [0,0]])\n",
        "I = np.eye(len(a))\n",
        "\n",
        "# no trade\n",
        "nt = np.eye(len(a)*2)\n",
        "\n",
        "# steal\n",
        "st = np.kron(S, I)\n",
        "\n",
        "# swap all\n",
        "sw = np.kron(X, I)\n",
        "\n",
        "# share\n",
        "sh = np.kron(X, I)/2 + np.eye(len(a)*2)/2\n",
        "\n",
        "\n",
        "# if it is being traded, a non zero in an off diagonal block. else identity\n",
        "# t = np.array([\n",
        "#   [1, 0, 0, 0.75],\n",
        "#   [0, 0.25, 0, 0],  # trade 0.75 x rid2 for 0.25 x rid1\n",
        "#   [0, 0.75, 1, 0],\n",
        "#   [0, 0, 0, 0.25]\n",
        "# ])\n",
        "\n",
        "\n",
        "\n",
        "print(a, b)\n",
        "trade(a, b, st)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 6 9 9] [8 3 0 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([15.,  9.,  9., 10.]), array([0., 0., 0., 0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "9hdbcHOKTSoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3bb12071-07e8-447a-e468-94ef09c88511"
      },
      "cell_type": "code",
      "source": [
        "# problem. what you say you want to trade might be different to what you want do trade? (might cheat?)\n",
        "\n",
        "def trade(r1, r2, t1, t2=None):\n",
        "  if t2 is None:\n",
        "    t2 = t1.T\n",
        "  return r1 - np.dot(t1, r1) + np.dot(t2, r2), r2 - np.dot(t2.T, r2) + np.dot(t1, r1)\n",
        "  \n",
        "  \n",
        "a, b = rnd.randint(0, 10, 4), rnd.randint(0, 10, 4)\n",
        "print(a, b)\n",
        "\n",
        "# no trade\n",
        "t = np.eye(4)\n",
        "\n",
        "\n",
        "\n",
        "# \n",
        "trade(a, b, rnd.permutation(np.eye(4)), rnd.permutation(np.eye(4)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 8 3 2] [9 5 5 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([8., 5., 4., 9.]), array([5., 8., 4., 0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "us-c_BocXTOp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def expected_reward(inputs):\n",
        "  \"\"\"\n",
        "  This is where trust and value is captured. \n",
        "  (some sort of decomposition would be nice!? potential value and likelihood)\n",
        "  \n",
        "  Since the inputs are who, how, what, ... then which ever gives the \n",
        "  best expected reward should be chosen.\n",
        "  If an agent always trades favourably, then we should learn to assign them a \n",
        "  high expected reward. Thus learning to pay attention to the `agent_id`, aka reputation.\n",
        "  \n",
        "  Args:\n",
        "    inputs (np.array): [agent_id, resourc_id_sell, resourc_id_buy]\n",
        "  \n",
        "  \"\"\"\n",
        "  # could start with table Q values?\n",
        "  pass\n",
        "\n",
        "def choose_action(agent):\n",
        "  \"\"\"\n",
        "  For now, only consider one for one trades?\n",
        "  Or use 0, 2, 4, 6, 8?\n",
        "  Will need to look into cts RL at some point?!\n",
        "  \"\"\"\n",
        "  for i in range(n_agents):  # for each potential buyer, who\n",
        "      for j in len(n_resources):  # for each items to sell\n",
        "        for k in len(n_resources):  # for each items to sell\n",
        "          Q[i,j,k] = expected_reward(i, j, k)\n",
        "  return np.argmax(Q + noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGmLwozWa-US",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_trading_scheme(t):\n",
        "  \"\"\"\n",
        "  A and B trade with C, but C rips A and B off. A and B tell D that C is a bad actor. \n",
        "  Next time C wants to make a trade, C chooses to trade with the agents who have \n",
        "  the best estimated reward (a tradeoff between price and trust?).\n",
        "\n",
        "  To maximise expected reward (via trust), E comes up with a trade system that ...\n",
        "\n",
        "  \n",
        "  Aka, we use our Q functions to provide gradients, or act as a fitness fn, to evaluate various trade dances!?\n",
        "  \"\"\"\n",
        "  \n",
        "  # How is t constructed/agreed upon?!? !!!\n",
        "  # Want to have each agent give some input/make a chose about t.\n",
        "  # But for starters maybe just generate randomly and select fittest?\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B4HTWRhHNw1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def diminishing_rewards(x):\n",
        "  \"\"\"\n",
        "  As x increases y increases in diminishing amounts.\n",
        "  This function is being used to caputre the increase in \n",
        "  skill of an agent as it harvests the same resource.\n",
        "  \"\"\"\n",
        "  # this should be normalised and bounded. need to find a better fn\n",
        "  # maybe discretise it to the natural numbers as well?\n",
        "  n = 1.1\n",
        "  return ((x+1)**(1-n) - 1)/(1-n)\n",
        "\n",
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x))\n",
        "\n",
        "def cross_entropy(x):\n",
        "  return -x*np.log(x) - (1-x)*np.log(1-x) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fpZJMm2KK34s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Would be faster (but maybe less intuitive) if I could\n",
        "# frame these calculations from a global perspective.\n",
        "# Batch them up into larger operations.\n",
        "\n",
        "class Agent():\n",
        "  def __init__(self, name, n_resources):\n",
        "    self.name = name\n",
        "    \n",
        "    self.n_resources = n_resources\n",
        "    self.rnd_explore = 0.5\n",
        "    \n",
        "    # harvest counts. counts the number of times each resources has been harvested.\n",
        "    self.harvest_counts = np.zeros(n_resources)\n",
        "    # the agents current resources\n",
        "    self.resources = np.zeros(n_resources)\n",
        "    \n",
        "    # the agents estimate of the value of resources\n",
        "    self.resource_values = rnd.random(n_resources)\n",
        "    # the agents estimate of ?\n",
        "    \n",
        "    \n",
        "  \"\"\"\n",
        "  HARVEST.\n",
        "  \n",
        "  Doesnt seem necessary for trading, but is necessary for specialisation?\n",
        "  \"\"\"\n",
        "  def harvest_resource(self, resource_id):\n",
        "    self.harvest_counts[resource_id] += 1\n",
        "    logger.info(\"{}\".format(self.harvest_counts))\n",
        "    # the increase in efficiency with experience is the key!?\n",
        "    resource = diminishing_rewards(self.harvest_counts[resource_id])\n",
        "    self.resources[resource_id] += resource\n",
        "    return resource\n",
        "  \n",
        "  def harvest_policy(self):\n",
        "    # decision should be made based on;\n",
        "    # who has what resources and what would they sell them for -- suppliers\n",
        "    # who wants what resources (and how much) -- demanders\n",
        "    # how much this agent values its own resourses.\n",
        "    \n",
        "    # all of that information should be captured in the \n",
        "    # current estimate of resource_values?!?\n",
        "    \n",
        "    \n",
        "    # this is a greedy policy. \n",
        "    # want more flexibility here? memory for capturing dynamics. a rnn?\n",
        "    return np.argmax(self.resource_values + self.rnd_explore*rnd.standard_normal(self.n_resources))\n",
        "  \n",
        "  def harvest(self):\n",
        "    # pick a resource and harvest it\n",
        "    self.harvest_resource(self.harvest_policy())\n",
        "  \n",
        "  def random_harvest(self):\n",
        "    # could use this to make things simpler?\n",
        "    self.resources += rnd.standard_normal(self.n_resources)\n",
        "    \n",
        "  \n",
        "  \"\"\"\n",
        "  TRADE.\n",
        "  \n",
        "  Necessary for collaboration? (but how resources are traded is still unconstrained)\n",
        "  (want to say) is sufficient for specialisation!?!? \n",
        "  \"\"\"  \n",
        "  def action_policy(self, agent_id, resources):\n",
        "    # actions: trade, cheat\n",
        "    # want to use EWA? init at 1.\n",
        "    a = rnd.randint(0,2)\n",
        "    logging.info(\"{}\".format(a))\n",
        "    return a\n",
        "  \n",
        "  def trade_policy(self):\n",
        "    return rnd.random(), rnd.random(), rnd.randint(0,self.n_resources), rnd.randint(0,self.n_resources)\n",
        "    \n",
        "  \n",
        "  def trade_resources(self, agent_id, resource_ids, supply=False, demand=False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      who is the agent trading with?\n",
        "      resource_id (tuple): (int, int) what is being traded for a for b\n",
        "    \n",
        "    \"\"\"\n",
        "    # so this happens in two rounds? \n",
        "    # 1. gather info from market (or use info from last time?)\n",
        "    # 2. \n",
        "    \n",
        "    # need to investigate how actual markets work... \n",
        "    # no. want to evolve this... but how!?\n",
        "    \n",
        "    v = self.resource_values[resource_ids]\n",
        "    a = np.argmax(self.action_policy(who, resource_ids, v))\n",
        "    \n",
        "    # ahh. there is another loop here!?\n",
        "    # accept reject various offers?\n",
        "    # v = \n",
        "    \n",
        "    return 0\n",
        "  \n",
        "  def trade(self, agent):\n",
        "    \"\"\"\n",
        "    This has a lot of details to be worked out!!\n",
        "    \"\"\"\n",
        "    trade_bool = self.action_policy(agent.name, agent.resources)\n",
        "    if trade_bool:\n",
        "      amount_a, amount_b, idx_a, idx_b = self.trade_policy()\n",
        "      self.resources[idx_b] -= amount_a\n",
        "      agent.resources[idx_a] += amount_b\n",
        "      # i dont like the statefulness here. \n",
        "      # would prefer to do something more functional!?\n",
        "      logging.info(\"Traded {} for {}\".format(idx_a, idx_b))\n",
        "  \n",
        "  \n",
        "  \"\"\"\n",
        "  VALUE\n",
        "  \"\"\"\n",
        "  def reward(self, true_resource_values):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      true_resource_values: Where are these coming from? Expect all to be positive?\n",
        "    \"\"\"\n",
        "    # is not additive?\n",
        "    # having LOTs of wood far less valuable than\n",
        "    # having some wood and a few nails\n",
        "    # want a good distribution over resources.\n",
        "    \n",
        "    # seems like it might be too complicated,\n",
        "    # what about building things out of resources? \n",
        "    # is that necessary to capture what I want to?\n",
        "    # it would relieve the need for some measure of distribution. \n",
        "    # could just reward production of 'valuable' items\n",
        "    \n",
        "    # this might be diffierentiable? not sure what to do with that...\n",
        "    \n",
        "    # what is the right metric here!?!\n",
        "    # return np.prod(v)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # want a single local (per agent) reward. which generates trade and specialisation! \n",
        "\n",
        "    v = self.resources * true_resource_values\n",
        "    h = cross_entropy(softmax(v))\n",
        "    return np.sum(h) + np.sum(v)  # additive relation, or multiplicative or ???\n",
        "\n",
        "  \n",
        "  def update_resource_values(self, supply, demand):\n",
        "    # could learn to do this?\n",
        "    self.resource_values = np.dot(supply, demand.T)\n",
        "  \n",
        "  def value_policy(self, ):\n",
        "    self.resource_values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "990NkBoj32WP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TradeDance():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def trade(self, A, B):\n",
        "    # problem is that A/B might need to learn how to use each different dance.\n",
        "    # (that brings us to three learning loops... how to use a dance, the dances, which dances to prefer)\n",
        "    self.dance()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bYlZdkYF8ayW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def simulate(dance):\n",
        "  # agents play with the trade dance.\n",
        "  # the figure out how to exploit their environment to maximise rewards\n",
        "  agents = init_agents()\n",
        "  \n",
        "  \n",
        "  # learn how to use the dance\n",
        "  for _ in range(dance_iters):\n",
        "    harvest()\n",
        "    \n",
        "    trade(dance)\n",
        "    agent.learn()\n",
        "    \n",
        "  # estimate steady state behaviour of the dance.\n",
        "  # how good is it at allowing the agents to get what they want?\n",
        "  return np.mean([agent.rewards for agent in agents])  # the average still works globally. want to make local!\n",
        "\n",
        "\n",
        "def evolve_trade():\n",
        "  dances = ga.generate()\n",
        "  for _ in iters:\n",
        "    sims = [simulate(dance) for dance in dances]\n",
        "    dances = ga.reproduce(dances, fitness=sims)  # agents prefer to use dances that \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "# simulations are nice. but how do they help us understand?\n",
        "# show that it is possible to learn X with A, but not possible with B.\n",
        "# calculate sensitivity to various parameters\n",
        "# ?\n",
        "# how can we bring some more math into this?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SO1AhXvU7Ssq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x_rG26y11chD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_resources = 12\n",
        "n_agents = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "My6z17SN7xce",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jiq8s6Fd7x8u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "5kTU-ZHZ-KUY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}