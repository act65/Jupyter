{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The neuromorphic computing community has similar goals to macine learning and work with artificial neural networks. To make ???\n",
    "Motivation!\n",
    "\n",
    "Ps. Hijacked with a lot of my own opinion?!?\n",
    "\n",
    "Disclaimer\n",
    "\n",
    "\n",
    "# Background\n",
    "\n",
    "### Memristors\n",
    "\n",
    "similarity to brains, synapses, ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Memcomputing Machine\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We define a memprocessor as an object defined by the four-tuple $(x,y,z,\\sigma)$ where x is the state of the memprocessor, y is the array of internal variables,z the array of variables that connect from one memprocessor to other memprocessors, and \u001b an operator that defines the evolution\n",
    "\n",
    "$\\sigma[x,y,z] = x', y' \\\\$\n",
    "\n",
    "In neural networks we have a few different types of memprocessor\n",
    "* Feedforward $\\sigma[x, w \\,and\\, b] = y $ although these do not seem to be an interesting version of memprocess. The only fit in the trivial case of ... \n",
    "* Recurrent $\\sigma[x,w \\,and\\, b, y^{t-1}] = y^t $... \n",
    "  * y = x for vanilla? \n",
    "  * LTSM... x = h(t), y = c(t), z = [h(t)], \\sigma = ?!?\n",
    "  * \n",
    "  \n",
    "### Memprocessors\n",
    "they define a memprocessor as \n",
    "\n",
    "$ x_{ex}(t) = g(x_{in},u(t),t)u(t) \\\\\n",
    "x_{in}(t) =f(x_{in},u(t),t) \\\\$\n",
    "\n",
    "Less cryptically, we can interpret this in terms of Voltage and Current, two complementary constituitive variables that they allude to.\n",
    "\n",
    "$ V = IR \\\\\n",
    "R(t) = g(R(t),I(t),t) \\\\\n",
    "V = g(R(t),I(t),t) I(t) \\\\\n",
    "\\frac{\\partial R}{\\partial t} = f(R(t),I(t),t)  \\\\$\n",
    "\n",
    "A good analogy to understand this ideas is the idea of water flowing through a pipe. However, the width of the pipe is a function of how much water has flown through it previously. Aka, the resistance to flow is a function of the past flow.\n",
    "\n",
    "And in our language, of weights etc..\n",
    "\n",
    "$ y = w \\cdot x  \\quad\\text{this isnt quite the same? dot product is not the same as times?} \\\\\n",
    "w(t) = g(w(t),x(t),t) \\\\\n",
    "y(t) = g(w(t),x(t),t) x(t) \\\\\n",
    "\\frac{\\partial w}{\\partial t} = f(w(t),x(t),t)  \\\\$\n",
    "\n",
    "where g() would be the activation function? no. not for time\n",
    "\n",
    "cool, this seem right.??\n",
    "### Evolution in time\n",
    "\n",
    "according to them the time evolution of the system\n",
    "$$w(t+T) - w(t) = \\int_{t}^{t+T} f(w(\\tau),x(w(\\tau),y(\\tau)),\\tau) \\partial \\tau$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Memelements(): #A network of memelements\n",
    "    def __init__(self,state = None, #the state of the memelement\n",
    "                 internal = None,   #the internal variables of the memelement\n",
    "                 connection = None, #the array of all connecting variables\n",
    "                 sigma = None):     #the operator that defines the evolution of the system\n",
    "        \n",
    "        self.x = state\n",
    "        self.y = internal\n",
    "        self.z = connection\n",
    "        self.s = sigma\n",
    "        \n",
    "    def evolve(self,t=1):\n",
    "        self.x, self.y = self.sigma(self.x,self.y,self.z,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neurons fit this general definition of a memelement as ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### A network of 3 linear neurons\n",
    "def f(x,y,z,t):\n",
    "    return y + np.dot(x,z) #?!?!?! some sort of convolution\n",
    "\n",
    "\n",
    "Mem = Memelement(1,2,3,sigma = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memcomputing machine\n",
    "\n",
    "Define \n",
    "$UMM = (M,\\Delta,P,S,\\Sigma, p0, s0,F)$\n",
    "Where;\n",
    "* M is the set of possible states. \n",
    "    * States are defined as \n",
    "* $\\Delta$ is the set of functions $\\delta_{\\alpha} : M^{m_{\\alpha}} \\setminus F \\times P \\rightarrow M^{m_{alpha}^{'}} \\times P^2 \\times S$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UniversalMemcomputingMachine():\n",
    "    def __init__(self,\n",
    "                 MEM = None,          #a network of memelements\n",
    "                 deltas = None,       #\n",
    "                 indexs = None,       #the set of indexes, ?\n",
    "                 init_states = None,  #\n",
    "                 init_pointers = None,#\n",
    "                 init_index = None,   #\n",
    "                 final = None         #\n",
    "                ):\n",
    "        \n",
    "        self.M = MEM\n",
    "        self.states = init_states\n",
    "        self.point = init_pointers\n",
    "        self.d = deltas\n",
    "        self.S = indexs\n",
    "        self.S_0 = init_index\n",
    "        self.F = final\n",
    "        \n",
    "    def step(self):\n",
    "        self.M.x = self.states #we need a pointer here???\n",
    "        self.M.evolve()\n",
    "        self.states,self.point,self.index = self.d[self.M.x[self.point]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrinsic parellelism\n",
    "\n",
    "What if we want to solve $(2+3) \\times (4+5^2) = ?$ and have a single ALU. Then to solve this we need to caluclate 5^2 first, then ... as each computation requires the same resource. This problem is removed by increasing the number of processors/ALUs and thus this computation can run in parallel. Thus we could increase the \n",
    "\n",
    "However\n",
    "Von neumann bottle neck and energy efficiency...\n",
    "\n",
    "### Functional polymorphism\n",
    "\n",
    "functional polymorphism <- but how does it know which ones to point to, to achieve a certain function?\n",
    "\n",
    "\n",
    "### Information overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Make a UMM\n",
    "init_states = np.random.random((4,3,3))\n",
    "pointerset = np.array(list(itertools.product(range(3), range(3))))\n",
    "\n",
    "def transition_function(state,pointer): #got to be a better way than this?\n",
    "    if state == states[0]:\n",
    "        return states[2], pointerset[[2,4,5,7]], 0\n",
    "    elif state == states[1]:\n",
    "        return states[2], pointerset[[2,4,5,7]], 1\n",
    "    elif state == states[2]:\n",
    "        return states[2], pointerset[[2,4,5,7]], 2\n",
    "\n",
    "UMM = UniversalMemcomputingMachine(Mem,transition_function,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Real world examples - Neuromorphic computing\n",
    "\n",
    "Knowm\n",
    "Adapteva\n",
    "Synapse?\n",
    "\n",
    "And papers showing it?\n",
    "\n",
    "# P = NP\n",
    "\n",
    "Exponentially expanding solution tree. (interactive pic?)\n",
    "Control unit specifies memprocessors to ??? ... \n",
    "\n",
    "## Subset sum problem\n",
    "\n",
    "Given a set of integers, is there a non-empty subset whose sum is zero?\n",
    "For example, given the set {−7, −3, −2, 5, 8}, the answer is yes because the subset {−3, −2, 5} sums to zero.\n",
    "This problem is NP-complete (both NP and NP-hard)\n",
    "\n",
    "Could be interesting to test this out on both a UTM and a UMM??\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Relation to quantum computers\n",
    "\n",
    "Memory = entangled probabilities\n",
    "Bohmian mechanics etc...\n",
    "\n",
    "\n",
    "# Future work and questions\n",
    "\n",
    "* Build one and test it on a few problems\n",
    "    * Make a NN and learn to solve Shor's algorithm in P with P\n",
    "* Developing the math of perfect memory convoluted events - explore\n",
    "\n",
    "\n",
    "Volatile memory, AHaH nodes, \n",
    "Boltzman machines, attractors - like contrastive divergence? Sampling - AC???\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
