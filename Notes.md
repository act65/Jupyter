# t-SNE
## Local structure vs global structure

Which is really the goal. 
* People like t-SNE because it seperates the classes into categories, but it seems to miss more of the local structure in doing so??? 
  * 1s that look like 4s... 6s that look like 0s? Or does it not?
* 

Coil20 t-SNE looks weird! What is the reason, and how does that picture help us understand the structure of the data?


# 311

## Learning math. 
* (Currently) the ideas are obvious, it is about learning the notation. 
 * The lecturers must think we are idiots, they are too focused on their average student passing the dumb it down too much. Thus the average student get bored anyway... Teaching occurs a lot slower.
 * And what are all the kids in my class thinking?!? Do they realise what the point of him droning on about how a = a, or ...
* So the metacognitive technique here would be that I need to figure out what the teacher is trying to teach.

# CS231n

The greater the depth the more the gradients vanish/explode. How do deep conv nets avoid this? Normalise the weights to be on average 1. Thus, between each layer $\delta \cdot w = \delta \cdot 1$. That applies to linear depth, but what about residual nets?
