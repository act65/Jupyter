{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a dataset $(x^i, y^i) \\in X \\times Y \\subset \\mathbb R^{n\\times m} \\times \\mathbb R^n$. Where $n$ is the number of distinct pairs of input, label and $m$ is the dimentionality of the problem.\n",
    "\n",
    "Our goal is to use this data to predict $Y^*$ for a set of inputs $X^* \\in \\mathbb R^{n\\times m}$. Naievly we could just use X, Y as a kind of _lookup table_ and take the label of the closest neighbor (_nearest neighbors_). (k-NN and ...?)\n",
    "\n",
    "Why is this bad?\n",
    "\n",
    "The redundancies in the data hint a a couple of ways to compress this dataset, while preserving accuracy.\n",
    "\n",
    "Thus this problem reduces down to one of representation. We want a representation that is;\n",
    "* fast to query, \n",
    "* easy to train, ...?? \n",
    "* able to deal with arbitrary data distributions, \n",
    "* able to learn incrementally in an online setting,\n",
    "* (has explicit/interpretable handles to decomposed knowledge, ...?)\n",
    "\n",
    "Why a tree and not a graph?\n",
    "\n",
    "What if we used quad or cover trees? The benefit of the boundary tree is that we can learn how to allocate resolution, rather than preassigning how we want to split space up. This gives an $\\mathcal O(???)$ speed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BoundaryTree():\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "        self.metric = None  # could be learned. or could be used on embeddings\n",
    "        \n",
    "    def query(self, x):\n",
    "        \"\"\"\n",
    "        Decend tree from root, picking the closest child as measured by some metric. \n",
    "        When we can go no further, return the label of the current node\n",
    "        \"\"\"\n",
    "        # not a trivial algorithm? \n",
    "        # could imagine a node that is closer, \n",
    "        # but a child of another node is still closer.\n",
    "        # i actually need to explore the tree?\n",
    "\n",
    "        current_node = self.root\n",
    "        while ?:\n",
    "            children = current_node.get_children()\n",
    "            if len(children) > 0:\n",
    "                nearest = max([(self.metric(child.value, self.x), child) \n",
    "                               for child in children], \n",
    "                              key=itemgetter(1))\n",
    "                current_node = nearest\n",
    "        \n",
    "        return current_node\n",
    "        \n",
    "    def add_node(self, parent, value, label):\n",
    "        \"\"\"\n",
    "        Adds a node to the tree.\n",
    "        \"\"\"\n",
    "        \n",
    "    def train(self, inputs, labels):\n",
    "        for x in inputs:\n",
    "            nearest = self.query(self, x, y)\n",
    "            if self.difference(y, nearest.label) > self.epsilon:\n",
    "                # if the label is different to the nearest node\n",
    "                self.add_node(nearest, x, y)\n",
    "        \n",
    "    def test(self, inputs, labels):\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How important are the positions of the roots? Do we need to carefully pick them?\n",
    "* Is it best to have wide (via a forest?) or deep trees?\n",
    "* What pathologies are there? And infinitely deep tree from alternating labels? Label noise could cause infinite density (unless we stored labels as a probability?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
