{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Hyperparameters\n",
    "S = 3 # *6*6 number of nodes in softmax layer\n",
    "layer_shapes = [(1,5),(5,10,),(10,20),(20,S)]\n",
    "strides = [1,2,1,2]\n",
    "\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Some helper functions to tidy things up\n",
    "\n",
    "#Define the variables in my network\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.2, shape=shape,dtype=tf.float32)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#Some convolutions\n",
    "def conv2d(x, W,stride):\n",
    "    if stride == 2:\n",
    "        pad = \"VALID\"\n",
    "    else:\n",
    "        pad = \"SAME\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1],padding =  pad)\n",
    "\n",
    "def conv(im,W,b,stride,shift,scale):\n",
    "    with tf.name_scope('conv'):\n",
    "        o = conv2d(im, W,stride) + b #convolve\n",
    "    with tf.name_scope('batch_norm'):\n",
    "        mean,var = tf.nn.moments(o,axes = [0]) #batch normalise\n",
    "        x = scale*(o-mean)/tf.sqrt(tf.square(var)+1e-7) + shift\n",
    "    with tf.name_scope('activation'):\n",
    "        return tf.nn.relu(x) #activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A layer in my net\n",
    "class Conv_layer():\n",
    "    def __init__(self,shapes,name,w=3,stride = 2,dropout = False):\n",
    "        K1,K2 = shapes\n",
    "        self.stride = stride\n",
    "        self.window = w\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        with tf.name_scope('params'+name):\n",
    "            self.weights = weight_variable([w,w,K1,K2])\n",
    "            self.biases = bias_variable([K2])\n",
    "            self.shift = tf.Variable(0.0)\n",
    "            self.scale = tf.Variable(1.0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        with tf.name_scope('layer'):\n",
    "            if self.dropout:\n",
    "                return tf.nn.dropout(conv(x,self.weights,self.biases,self.stride,self.shift,self.scale), keep_prob)\n",
    "            else:\n",
    "                return conv(x,self.weights,self.biases,self.stride,self.shift,self.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define inputs and outputs\n",
    "with tf.name_scope('inputs'):\n",
    "    image = tf.placeholder(tf.float32, shape=[None, 28,28,1])\n",
    "    lab = tf.placeholder(tf.int64, shape=[None, 1])\n",
    "    y_ = tf.one_hot(lab,10,0.0,1.0)\n",
    "    y_ = tf.reshape(y_,[batch_size,10])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "### Generate the layers for our network\n",
    "net = []\n",
    "for i,shape in enumerate(layer_shapes):\n",
    "    net.append(Conv_layer(shape,str(i),stride = strides[i]))\n",
    "\n",
    "with tf.name_scope('softparams'):\n",
    "    W_soft = weight_variable([S*6*6, 10])\n",
    "    b_soft = bias_variable([10])\n",
    "    \n",
    "### Connect the computational graph\n",
    "n=len(net)\n",
    "outputs = (n+1)*[None]\n",
    "outputs[0] = image\n",
    "for i in range(n):\n",
    "    outputs[i+1] = net[i].forward(outputs[i])\n",
    "    \n",
    "with tf.name_scope('softmax'):\n",
    "    y_conv = tf.nn.softmax(tf.matmul(tf.reshape(outputs[n],[batch_size,S*6*6]),W_soft) + b_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Loss and training\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "    tf.scalar_summary('cross_entropy',cross_entropy)\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.scalar_summary('accuracy',accuracy)\n",
    "    \n",
    "with tf.name_scope('trainer'):\n",
    "    train_step = tf.train.RMSPropOptimizer(0.01, momentum = 0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def update_rule(loss,param,eta):\n",
    "#     with tf.name_scope('grads'):\n",
    "#         grads = tf.gradients(loss,param)\n",
    "    \n",
    "# eta = []\n",
    "\n",
    "# with tf.name_scope('optimiser'):\n",
    "#     for param in parameters:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Get some data\n",
    "from fuel.datasets import MNIST\n",
    "mnist = MNIST(('train',))\n",
    "state = mnist.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summaries_dir = '/Volumes/ExtraDiskSpace/Documents/CS231n/TF/grads'\n",
    "\n",
    "if tf.gfile.Exists(summaries_dir):\n",
    "    tf.gfile.DeleteRecursively(summaries_dir)\n",
    "tf.gfile.MakeDirs(summaries_dir)\n",
    "\n",
    "merged = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 207.201\n",
      "0.1 207.452\n",
      "0.0 207.138\n",
      "0.1 207.123\n",
      "0.2 207.4\n",
      "0.1 207.098\n",
      "0.0 207.75\n",
      "0.0 207.18\n",
      "0.0 207.417\n",
      "0.0 207.069\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    writer = tf.train.SummaryWriter(summaries_dir,sess.graph)\n",
    "    \n",
    "    \n",
    "    requests = [[np.random.randint(1,5000) for n in range(batch_size)] for epoch in range(10)]\n",
    "    for req in requests:\n",
    "        count +=1\n",
    "        im,labels = mnist.get_data(state=state, request=req)\n",
    "        im = im.reshape((batch_size,28,28,1))/255\n",
    "        feed = {image: im, lab: labels, keep_prob: 1.0}\n",
    "\n",
    "        _,acc,loss,y,x = sess.run([train_step,accuracy,cross_entropy,y_conv,outputs[1]], feed_dict= feed)\n",
    "        print(acc,loss)\n",
    "\n",
    "        summary = sess.run(merged,feed_dict=feed)\n",
    "        writer.add_summary(summary,count)\n",
    "\n",
    "        #G = sess.run(grads, feed_dict= feed)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
