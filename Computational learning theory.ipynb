{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I think) there are four fundamental factors that constrains a learner.\n",
    "\n",
    "> * <i>What it does (model and capacity)\n",
    "* What it does it to (data and environment)\n",
    "* How well it does it (accuracy and error)\n",
    "* How efficiently it does it (computations, time, memory, energy)</i>\n",
    "\n",
    "What is learnable? Does it depend solely on the data? Or the ... No, it is depedent on all factors.\n",
    "\n",
    "<!--Need a simple example.-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model/Capacity\n",
    "\n",
    "* Proofs that increases in capacity give greater generalisation error.\n",
    "    * So we need simple structures that somehow match the structure of our problem.\n",
    "    \n",
    "    \n",
    "hypotheses and falsification??\n",
    "scientific method?\n",
    "\n",
    "* VC is just about existience. (proving a lower bound is easier than proving an upper bound. need to show there exists one set that shatters the inputs, vs need to prove there doesnt exist ... that shatters\n",
    "\n",
    "* what happens when hypothesis class doesnt contain the target class? (or the target class is exponentially hard to model in the given hypothesis class)\n",
    "\n",
    "* syntactic hypothesis space (all possible hypotheses you can write). semantic hypothesis space (actual different functions you can practiaclly represent)\n",
    "\n",
    "* A model's hypothesis (possibly some parameters) can be something quite different to a hypothesis about the real world (???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "How much?\n",
    "What form? (batch?, online?)\n",
    "What accuracy can we measure it?\n",
    "Margin, separability, ... ?\n",
    "sample complexity\n",
    "\n",
    "\n",
    "Learner chooses. Teacher chooses. Nature chooses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error\n",
    "\n",
    "mistake bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doublets\n",
    "\n",
    "##### Model+Data = Capacity (and Representations and invariance?)\n",
    "\n",
    "Traditional learning (from 90s) ... VC\n",
    "\n",
    "What structure... suits the data. E.g. convolutions for images.\n",
    "How doe structure in our data constrain/select the structure we should use in our learners?\n",
    "\n",
    "\n",
    "##### Model+Efficiency = Computational complexity\n",
    "\n",
    "\n",
    "\n",
    "##### Model+Error = Generalisation\n",
    "\n",
    "\n",
    "How does capacity effect generalisation and/or ability to approximate?\n",
    "Telgarsky\n",
    "\n",
    "##### Data+Efficiency = Attention\n",
    "\n",
    "\n",
    "\n",
    "##### Data+Error = Statistical learning theory\n",
    "\n",
    "\n",
    "##### Efficiency+Error = Online Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Triplets\n",
    "\n",
    "##### Error-Capacity-Data\n",
    "\n",
    "##### Error-Data-Efficiency\n",
    "\n",
    "##### Error-Capacity-Efficiency\n",
    "\n",
    "Optimisers designed for NNs.\n",
    "\n",
    "##### Data-Capacity-Efficiency\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unification -- quadruplet\n",
    "\n",
    "Without proving something in all domains, you end up proving nothing. Take []() for examle, ... but does it actually learn faster and more accurately?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open problems\n",
    "\n",
    "* Evolution\n",
    "    * Could it have happened in the alloted time?\n",
    "* Cognition\n",
    "    * \n",
    "* Physics -- Constrains what is actually possible. \n",
    "    * Base all four factors in physics (using information? or energy?)\n",
    "        * Efficiency -> computations, energy, reverisible ...\n",
    "        * Data -> need to measure, collect, store, \n",
    "        * Model -> needs to be realisable and maintainable (error correcting architectures??)\n",
    "        * Error -> ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques\n",
    "\n",
    "Proving lower bounds\n",
    "* How?!?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes\n",
    "\n",
    "### Probably approximately correct\n",
    "\n",
    "Consider a finite hypothesis class H, a Boolean function $f : S \\rightarrow \\{0, 1\\}$ in H, and a sample distribution D over S, as well as an error rate $\\epsilon > 0$ and failure probability $\\delta > 0$ that the learner is willing to tolerate. \n",
    "\n",
    "Call a hypothesis $h : S \\rightarrow \\{0, 1\\}$ “good” if \n",
    "$$Pr_{x\\sim D}[h(x) = f (x)] ≥ 1−\\epsilon$$\n",
    "\n",
    "Also, call sample points $x_1, . . . ,x_m$ “reliable” if any hypothesis $h \\in H$ that satisfies $h(x_i) = f (x_i)$ for all $i \\in \\{1, . . . ,m\\}$ is good. Then $m = 1 \\epsilon ln \\mid H\\mid \\delta$ sample points $x_1, . . . ,x_m$ drawn independently from D will be reliable with probability at least $1−\\delta$.\n",
    "\n",
    "[L. G. Valiant. A theory of the learnable.]()\n",
    "\n",
    "\n",
    "The second drawback of Theorem 2 is that it gives us no clues about how to find a hypothesis h ∈ H consistent with the sample data. All it says is that, if we find such an h, then h will probably be close to the truth. This"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "* In a sense that can be made precise, learning and cryptography are “dual” problems: a learner wants to find patterns in data, while a cryptographer wants to generate data whose patterns are hard to find. (aaronson)\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjectures\n",
    "\n",
    "!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
