{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Piecewise linear curves](#curves)\n",
    "* Flat activations\n",
    "* [Decomposition](#decomposition)\n",
    "* Orthogonal functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flat activations\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "min \\; F(w) &= \\mathbb E_x \\big[(u(w^Tx)−y(x))^2\\big] \\\\\n",
    "\\nabla F(w) &= \\mathbb E_x \\big[(u(w^Tx)−y(x))\\cdot u'(w^Tx)\\cdot x\\big] \\\\\n",
    "&= \\mathbb E_x \\big[\\frac{\\partial F}{\\partial z}\\frac{\\partial z}{\\partial u}\\frac{\\partial u}{\\partial x} \\big] \\\\\n",
    "\\nabla F(w) &= \\mathbb E_x \\big[(u(w^Tx)−y(x))\\cdot x\\big] \\\\\n",
    "&= \\mathbb E_x \\big[\\frac{\\partial F}{\\partial z}\\frac{\\partial u}{\\partial x} \\big] \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "What!?!? You cant do that...\n",
    "\n",
    "\n",
    "\n",
    "How does this relate to finite differences!?\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla F(w) &= \\mathbb E_x \\big[(u(w^Tx)−y(x))\\cdot x\\big] \\\\\n",
    "&= \\mathbb E_x \\big[(u(w^Tx)−u(\\hat w^Tx))\\cdot x\\big] \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "hmm. what is that x doing there? oh. its a finite difference on w. then just chain rule?\n",
    "$$\n",
    "\\begin{align}\n",
    "\\nabla f(x) &= \\lim_{h\\rightarrow 0} \\frac{f(x+h) - f(x)}{h} \\\\\n",
    "\\nabla f(x) &\\approx \\big(u(w^T(x+h))−y(x+h)\\big)^2 - \\big(u(w^T(x))−y(x)\\big)^2 \\\\\n",
    "min \\; F(w) &= \\mathbb E_x \\big[(u(w^Tx)−y(x))^2\\big] \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "still dont get the mul by x?\n",
    "like a counter factual?\n",
    "\n",
    "how does this solve anything? the finite difference should still be zero in most places? i guess that depends on the step size, which in this case is the distance from the optimal setting of weights, so it should help convergence to the nearest zero-region which the target is in?\n",
    "\n",
    "Non-differential functions don't have gradients..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Decomposition\n",
    "\n",
    "Let $f(x) = CNN(x)$ and $g(z) = MLP(z)$ then let $z = f(x),y = g(z)$. $\\hat y, y \\in A; \\hat z, z \\in B$\n",
    "\n",
    "So B is a set of k binary labels. A is a binary label, the parity of z.\n",
    "\n",
    "* In the end-to-end setting find $\\mathop{argmin}_{\\theta, \\phi} \\;\\mathcal L_A \\big(\\hat y, g_\\theta(f_\\phi(x))\\big)$\n",
    "* In the decomposition setting find $\\mathop{argmin}_{\\theta, \\phi} \\;\\mathcal L_A \\big(\\hat y, g_\\theta(f_\\phi(x))\\big) + \\mathcal L_B \\big(\\hat z,f_\\phi(x)\\big)$\n",
    "\n",
    "Just learning on the parity is super hard. (why). many possible inputs that could give the the same result (a name for this?! - many-to-one). Very weak signal to learn from, reminds me of RL. However, labels of each image also have many-to-one, why does this feel different? ??? No gradient will help, just need to explore? That isnt true.\n",
    "\n",
    "Just btw, how could a 2 layer net implement a parity function?!?!\n",
    "\n",
    "We pay extra labels to learn faster/easier. (but which??? it is an important difference! which is cheaper over all?)\n",
    "\n",
    "Their experiments are not convincing at all. How can we be sure that the end-to-end meothd couldn't achieve high accuracy? How extensively did you search fora good  set of hyper parameters?\n",
    "\n",
    "What we really want to show is that the space of viable hyperparams is smaller for the end-to-end approach. We need to quantify how much harder it is to train.\n",
    "\n",
    "> In contrast, our analysis indicates that the problem is not due to local-minima (or saddle points), but from the gradients being non-informative and noisy\n",
    "\n",
    "Not clear it is a failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonal functions\n",
    "\n",
    "$\\mathbb E \\big[ h(x)h'(x) \\big]$ implies no correlation, is this the same as orthogonal? (they mentioned inner product in the infinite dimensional functional space -- ?!?) Does two random normal functions satisfy this?\n",
    "\n",
    "$$\n",
    "Var(H,F,w) = \\mathbb E \\Big[\\parallel \\nabla F_h(w)− \\;\\mathbb E_{h'} \\big[\\nabla F_{h'} (w)\\big] \\;\\parallel \\Big]^2\n",
    "$$\n",
    "\n",
    "* such that $h \\neq h'$?\n",
    "* was thinking about it wrong. we cannot pick some subset of $\\mathcal H$, it is the total size of the hypothesis class.\n",
    "* in english. Var(H, F, w) = the variance of the gradients (of the loss fn -- F -- w.r.t w) at some point (in parameter space, w).\n",
    "\n",
    "What does it look likes as we increase $\\mid \\mathcal H \\mid$? The loss surface/distribution of directions ... ??? concentrates on !?? where do the tend to?\n",
    "\n",
    "Supposedly related to having very flat loss surface, but i dont yet see the connection...\n",
    "\n",
    "Why is exponentially small variance a problem? Because calculating $\\nabla F_h(w)$ tells you about the same (up to an exponential factor) as $\\nabla F_{h'}(w)$. So if we wanted to learn $F_h$ then $\\nabla F_h(w)$ can't help us (much) to distinguish between $F_h$ and $F_{h'}$ \n",
    "\n",
    "Supposedly other work has found similar results for parities. So does this only apply to parities?? \n",
    "Parities are not a continuious function, what does that mean here?\n",
    "\n",
    "\n",
    "__What if we scaled the depth (rather than width) with d?__\n",
    "\n",
    "The paper used $10d > \\frac{2}{3}d$ to scale the width of the fully connected layer with $h\\in \\{0, 1\\}^d$ with $\\mid \\mathcal H \\mid$. \n",
    "\n",
    "The problem was the the density of hypotheses was incresing faster (in the size of H) than the ability of the parameters to separate them. If we increase the rate of representational capacity faster (through depth) then it would solve this problem?\n",
    "\n",
    "Not necessarily a failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failures of this paper.\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My failures of deep gradient-based learning.\n",
    "\n",
    "* Quick learning from a few examples. Pictures of people at the gym. Most there are pics of people holding/using dumbells. However, there are a very small number of arms without dumbells. We should be able to disentangle these two (arms, dumbells) as soon as we get a couple of examples of just arms. Or just dumbells.\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
