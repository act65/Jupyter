### Intro

##### Material

The introduction to the course. What is machine learning, some applications and how are we going to come at it. What are we going to learn and how are we going to be assessed.

##### Thoughts on the teaching

I liked;
* that you ran the course outline past us, and let us/asked us to give some input. It felt like we have more of a say in what we are going to learn and how. I feel empowered. (dont know if this was by design or disorganisation... but it was good)
* Getting two people to lecture the class tomorrow. Sets a great precedent for; diving into new topics, not feeling pressure to be great, ...?

Improvements(?);
* Could have done with more inspiration. Interesting point you made "_ I dont want to act as a repository for interesting resources, as I want others to go out and find it._" Chicken and egg problem? Need to inspire them first, so they will be motivated to find interesting stuff?
* Get to know class members? Everyone introduces themselves? Why are they taking the course?


*****

### Strawman

##### Material

Two students did the lecturing. A couple of very simple algorithms.
k-NN. So in the learning phase of this algorithm you... save the data into memory, done.

k-means. Iterative.
PCA (did we end up covering this... forgot)

##### Thoughts on the teaching

Was fun. Ideally the students would also have looked at some material on what is being
At one point you took over from one of the lecturing students and he kind of just stood up the front. I think you should have given him the opportunity to try to answer it (whatever the question was). Hopefully, if he does a bad job other students will point it out, or you can come in.

*****

### Perceptrons and the curse

##### Material

A perceptron. Linear threshold. A decision hyperplane -> we know that w.x = 0 if w and x are perpendicular, and is negative if pointing in different directions ... So really we are trying to find the optimal angle between w and the average x (?). How does the loss function $\frac{1}{2}(y - w.x)^2 $ tell us to find this angle?

The curse. $V_i = 2\pi/n V_{i-2}$. A unit circle in a unit square. In 20 dimensions the vast majority of the volume is in the corners of the unit square and almost none is in the circle.
Marcus mentioned that you could figure this out by randomly sampling points and seeing that they will almost always not be in the unit sphere. Is this true? So because it is unlikely it means the volume is small? This link doesnt seem obvious/clear.

##### Thoughts on the teaching

More disorganised than before.
I think the perceptron is a great canidate for people to go away and implement. Shouldnt bother lecturing it.
The curse of dimensionality wasnt linked into ML problems.

*****
###
##### Material
##### Thoughts on the teaching

*****
###
##### Material
##### Thoughts on the teaching