{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal. Learn the transition fn for a complex dynamical system.\n",
    "\n",
    "A few moving parts. (vaugely inspired by the successor representation)\n",
    "\n",
    "__Online clustering__ that starts simple and increases the number of clusters.\n",
    "- Could cluster by reward.\n",
    "- Want it to be density based!\n",
    "\n",
    "__Transition approximation__ that can be learned and transferred.\n",
    "- Given a clustering algol on a dynamical system, learn a simpler transition fn. A reduced representation.\n",
    "- Given a new clustering, $C_{new}$, which was derived from $C_{old}$. And given $T_{old}$ which learned to capture the dynamics under $C_{old}$, construct $T_{new}$ using the knowledge we have.\n",
    "    - if a cluster is split in two, then init both with the same transition fns and let them diverge as necessary.\n",
    "    - if a new cluster overlaps two old ones, then !?!?\n",
    "    \n",
    "    \n",
    "***\n",
    "\n",
    "Matrices are really nice as they make it easy to transfer the knowledge.\n",
    "If node/cluster $d$ recieved from $a$ and projected to $e, f$. Then when we init the new clusters, $d_1, d_2$ we can initialise them with the same signature as $d$.\n",
    "\n",
    "Which other representations make this easy? How can this be done with a neural network?\n",
    "If $t: S \\rightarrow S$ is some transition function, and $t^*$ is our approximation, then how can we transfer knowledge in the NN to ...?\n",
    "\n",
    "***\n",
    "\n",
    "$$\n",
    "y(t) = f(y_t-1, dy_t-1, ...?)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicalSystem():\n",
    "    \"\"\"\n",
    "    Want something related to DFAs.\n",
    "    \n",
    "    For now, just binarise the states.\n",
    "    \n",
    "    TODO;\n",
    "    - generate non linear systems\n",
    "    - find a nice system, a complex graph or something, with meaningful nodes\n",
    "    - ?\n",
    "    \"\"\"\n",
    "    smap = {0:' ', 1:'.'}\n",
    "    \n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "        \n",
    "        self.state = np.zeros(n)\n",
    "        self.state[np.random.randint(0, self.n)] = 1\n",
    "        \n",
    "        # could make a sparse matrix to be more efficient?\n",
    "        self.G = np.random.randint(-2, 2, (n, n))\n",
    "        self.G = (0.5/(n**2)*(np.random.standard_normal((n, n)) > 1).astype(np.int32) \n",
    "                  - 0.5/(n**2)*(np.random.standard_normal((n, n)) > 1).astype(np.int32))\n",
    "        \n",
    "    @staticmethod\n",
    "    def tostring(x):\n",
    "        return ''.join([DFA.smap[s] for s in x])\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.tostring(self.state)\n",
    "    \n",
    "    def step(self):\n",
    "        self.state = (np.dot(self.G, self.state) > 0).astype(np.int32)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state = np.zeros(self.n)\n",
    "        self.state[np.random.randint(0, self.n)] = 1\n",
    "        \n",
    "    def show(self):\n",
    "        plt.imshow(self.G, interpolation='nearest', cmap='gray')\n",
    "        \n",
    "        \n",
    "class Encoder():\n",
    "    \"\"\"\n",
    "    Want to learn this encoder, but for now, just use rnd projection.\n",
    "    \n",
    "    TODO;\n",
    "    - learn online\n",
    "    - look into neural discrete representations \n",
    "    (could be as simple as just adding a new vector to memory?)\n",
    "    https://gist.github.com/act65/edf2627b42ee570fe2ea36d8e33f7b88\n",
    "    https://deepmind.com/research/publications/neural-discrete-representation-learning/\n",
    "    - \n",
    "    \"\"\"\n",
    "    def __init__(self, n, d):\n",
    "        self.n = n\n",
    "        self.d = d\n",
    "        self.proj = np.random.standard_normal((d, n))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return (np.dot(self.proj, x).T > 0).astype(np.int32)\n",
    "    \n",
    "    def add_cluster(self):\n",
    "        self.proj = np.vstack([self.proj, np.random.standard_normal((1, self.n))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7facaf74c668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 32\n",
    "d = 12\n",
    "ds = DFA(n)\n",
    "ds.show()\n",
    "\n",
    "enc = Encoder(n, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      .                          ---  . ....... .\n",
      "  . .  .    .     .....  .     . ---  ...... . ..\n",
      "..   .... . ...    .  ..  . .    --- ...... .. ..\n",
      "  ..   .. . .   .. .. .   .  . . --- . .. ..   ..\n",
      "....   .... ..  .. .   .  . ..   --- . .. .  . ..\n",
      "  ..   .... .    .        .  . . --- . .  .  . ..\n",
      " ..     ... .    .        . .. . --- . .  .  . . \n",
      "  ..   .... .  . . .   .  . .. . ---   ....  .   \n",
      " ...    ... .  . .        . .. . ---   .  .  . . \n",
      " ...   .... .  . .        .  . . --- . .  .  . ..\n"
     ]
    }
   ],
   "source": [
    "dfa.reset()\n",
    "for i in range(10):\n",
    "    print(dfa, '---', dfa.tostring(enc(dfa.state)))\n",
    "    dfa.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          .                       --- .. ... .  .  \n",
      "  .       . .             .  .    --- . .. .. .   .\n",
      " ..     ...        .  .   . ..    --- . .  .  . .  \n",
      "  .     ...      . .   .     . .  ---   . ..  .    \n",
      " ..  . .... .  . ..    .  . .. .  --- . .  .  . . .\n",
      " ...   .... .   .. .  .     .. .  --- . .  .  . ...\n",
      "....   .... .    .        .  . .  ---   . ..  . .. \n",
      " ..    .. . .    .        .  . .  --- . .  .  . .. \n",
      " ..    .... .   .. .   . .. ..    --- . .  .. . .. \n",
      "  ..   .... .    . .   .  .  . .  --- . .. .  . .  \n"
     ]
    }
   ],
   "source": [
    "enc.add_cluster()\n",
    "dfa.reset()\n",
    "for i in range(10):\n",
    "    print(dfa, '---', dfa.tostring(enc(dfa.state)))\n",
    "    dfa.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approximator():\n",
    "    \"\"\"\n",
    "    \n",
    "    TODO;\n",
    "    - need a way to transfer knowledge given knowledge about where to transfer\n",
    "    - want a more powerful representation (non linear fn approximator)\n",
    "    - ?\n",
    "    \"\"\"\n",
    "    def __init__(self, n, approx=None):\n",
    "        self.n = n\n",
    "        self.W = np.random.standard_normal((n, n))\n",
    "        self.dL = grad(self.loss)\n",
    "        \n",
    "    @staticmethod\n",
    "    def loss(W, x, t):\n",
    "        # this doesnt seem fair. the dfa uses a different fn to generate the seq\n",
    "        y = np.dot(W, x)  \n",
    "        return np.sum((t-y)**2)\n",
    "    \n",
    "    def __call__(self, x):  \n",
    "        return (np.dot(self.W, x) > 0.5).astype(np.int32)\n",
    "        \n",
    "    def train(self, x, t):\n",
    "        self.W -= 0.001 * self.dL(self.W, x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Approximator(3)\n",
    "x = np.random.random((3, 1))\n",
    "t = np.random.random((3, 1))\n",
    "app.train(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 128\n",
    "d = 16\n",
    "dfa = DFA(n)\n",
    "enc = Encoder(n, d)\n",
    "app = Approximator(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.386233162502998"
     ]
    }
   ],
   "source": [
    "def train(dfa, enc, app, epochs=500):\n",
    "\n",
    "    for e in range(epochs):\n",
    "        dfa.reset()\n",
    "        old_obs = enc(dfa.state)\n",
    "        for i in range(20):\n",
    "            dfa.step()\n",
    "            obs = enc(dfa.state)\n",
    "            app.train(old_obs, obs)\n",
    "\n",
    "            loss = app.loss(app.W, old_obs, obs)\n",
    "    #         loss = np.linalg.norm(app.W-dfa.G)\n",
    "            print('\\rloss: {}'.format(loss), end='', flush=True)\n",
    "            old_obs = obs\n",
    "    return app\n",
    "            \n",
    "app = train(dfa, enc, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want batch training!?\n",
    "# online training is unnecessarily complicating things?\n",
    "def run(dfa, n):\n",
    "    for i in range(20):\n",
    "        dfa.step()\n",
    "        obs = enc(dfa.state)\n",
    "    return np.array([dfa.step()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".   ....  ... ..  --- ......... ......\n",
      "     ....  . .    ---     .  ..       \n",
      "    .. .....  ..  --- ..  .  .. .  ...\n",
      ".   .. .. .. . .  --- ..  .  .. .. ...\n",
      " .    ... .. .    ---  .  .  .. .    .\n",
      " .   . .  ..  ..  --- ..  .  .. ..  ..\n",
      " .  .. .. ..  ..  --- ..  .  .. .. ...\n",
      ".   .  .  .   .   ---  .        .   ..\n",
      " .       ... ..   --- ..     .  .   . \n",
      "...    .  ..  .   ---  .     .. ..  ..\n"
     ]
    }
   ],
   "source": [
    "dfa.reset()\n",
    "for i in range(10):\n",
    "    c = enc(dfa.state)\n",
    "    y = app(c)\n",
    "    dfa.step()\n",
    "    print(dfa.tostring(c), '---', dfa.tostring(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.add_cluster()\n",
    "app = Approximator.transfer(old_enc, new_enc, app)  # construct new approx. how!?\n",
    "app = train(dfa, enc, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
