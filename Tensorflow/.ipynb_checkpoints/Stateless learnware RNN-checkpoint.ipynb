{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dont know what i think so far. I am adding more parameters, but now the can learn different non-linearities. Adding more parameters will lead to over fitting? But i can just reduce the nets size?\n",
    "\n",
    "I could tie weights across\n",
    "* neurons?\n",
    "* read/write????\n",
    "\n",
    "Based on \n",
    "* Balduzzi - Strongly typed RNNs\n",
    "* and Neural Turing Machines.\n",
    "\n",
    "\n",
    "Permutations\n",
    "* Additive, multiplication\n",
    "* Walks through weight space, aka the environment\n",
    "\n",
    "Analogy\n",
    "* Memory = environment\n",
    "* Weights = position in environment\n",
    "* Neurons = ants, particles, ??\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "n_inputs = 28\n",
    "n_hidden = 0\n",
    "n_outputs = 10\n",
    "m = n_inputs + n_hidden + n_outputs #number of memory cells\n",
    "\n",
    "n = 10#number of neurons\n",
    "\n",
    "time_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neurons that dont have a state\n",
    "class Neurons():\n",
    "    def __init__(self,n):\n",
    "        self.alphas = tf.Variable(np.ones((n,1),dtype=np.float32),'alpha')\n",
    "        self.betas = tf.Variable(np.ones((n,1),dtype=np.float32),'beta')\n",
    "        \n",
    "    def forward(self,phi):\n",
    "        return  tf.sigmoid(phi*self.betas) *  self.alphas#tf.exp(phi*self.betas) *self.alphas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape = [n_inputs,n_inputs])\n",
    "y_ = tf.placeholder(tf.float32, shape = [n_outputs,1])\n",
    "\n",
    "#The environment where signals interact.\n",
    "memory = tf.Variable(np.ones((m,1),dtype=np.float32),'Memory') \n",
    "\n",
    "#The weights. Do we want these to be symmetric? Do we want to learn these?\n",
    "read = tf.Variable(tf.random_normal((n,m)),'ReadConnectionWeights')\n",
    "write = tf.Variable(tf.random_normal((m,n)),'WriteConnectionWeights')\n",
    "biases = tf.Variable(np.ones((n,1),dtype=np.float32),'Biases')\n",
    "\n",
    "neurons = Neurons(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cell(inputs, memory):\n",
    "    #with tf.VariableScope('Basic'):\n",
    "    # Inputs\n",
    "    i = tf.slice(memory, [0,0],[n_inputs,1])\n",
    "    j = tf.slice(memory, [n_inputs,0], [m-n_inputs,1])\n",
    "    i = i * inputs\n",
    "    mem = tf.concat(0,[i,j])\n",
    "\n",
    "    ### Dynamics\n",
    "    #the inputs to our neurons. \n",
    "    phi = tf.matmul( read , mem ) + biases #nxm x mx1 = nx1\n",
    "    #the inputs to our memory cells. \n",
    "    psi = tf.matmul( write , neurons.forward(phi) ) #mxn x nx1 = mx1\n",
    "\n",
    "    return psi*memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"RNN\"):\n",
    "    for t in range(time_steps):\n",
    "        if time_steps > 0:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        memory = cell(tf.slice(x, [0,t],[-1,1]), memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Classification\n",
    "s = tf.slice(memory, [m-n_outputs,0],[n_outputs,1]) #take the outputs\n",
    "W_soft = tf.Variable(tf.random_normal((n_outputs,n_outputs)))\n",
    "b_soft = tf.Variable(np.zeros((n_outputs,1),dtype = np.float32))\n",
    "y = tf.matmul(W_soft,s) + b_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Loss and optimisation\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y), reduction_indices=[0])\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 1)\n",
      "(10, 1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "ans = sess.run([memory,y],feed_dict={x : np.ones((n_inputs,n_inputs),dtype = np.float32),y_ : np.ones((n_outputs,1),dtype = np.float32) })\n",
    "for a in ans:\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.1492\n",
      "22.0626\n",
      "105.035\n"
     ]
    }
   ],
   "source": [
    "for a in ans:\n",
    "    print(np.mean(np.abs(a)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
